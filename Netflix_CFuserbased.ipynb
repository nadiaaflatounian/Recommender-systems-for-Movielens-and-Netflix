{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>MovieAge</th>\n",
       "      <th>user_activity</th>\n",
       "      <th>AverageMovieAgeRated</th>\n",
       "      <th>user_average_rating</th>\n",
       "      <th>average_rating_per_movie</th>\n",
       "      <th>number_of_ratings_per_movie</th>\n",
       "      <th>scaled_movie_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.473012</td>\n",
       "      <td>1.640503</td>\n",
       "      <td>3.253308</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.031355</td>\n",
       "      <td>1.405855</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.077044</td>\n",
       "      <td>1.400853</td>\n",
       "      <td>3.873563</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.275924</td>\n",
       "      <td>1.525706</td>\n",
       "      <td>3.634304</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1.139754</td>\n",
       "      <td>1.326786</td>\n",
       "      <td>3.917197</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.172043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
       "0        1     1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
       "1        1      822109       5  2005-05-13           2003  Dinosaur Planet   \n",
       "2        1      885013       4  2005-10-19           2003  Dinosaur Planet   \n",
       "3        1       30878       4  2005-12-26           2003  Dinosaur Planet   \n",
       "4        1      823519       3  2004-05-03           2003  Dinosaur Planet   \n",
       "\n",
       "   RatingYear  MovieAge  user_activity  AverageMovieAgeRated  \\\n",
       "0        2005         2       1.473012              1.640503   \n",
       "1        2005         2       1.031355              1.405855   \n",
       "2        2005         2       1.077044              1.400853   \n",
       "3        2005         2       1.275924              1.525706   \n",
       "4        2004         1       1.139754              1.326786   \n",
       "\n",
       "   user_average_rating  average_rating_per_movie  number_of_ratings_per_movie  \\\n",
       "0             3.253308                  3.910534                     1.010541   \n",
       "1             4.083333                  3.910534                     1.010541   \n",
       "2             3.873563                  3.910534                     1.010541   \n",
       "3             3.634304                  3.910534                     1.010541   \n",
       "4             3.917197                  3.910534                     1.010541   \n",
       "\n",
       "   scaled_movie_age  \n",
       "0          1.215054  \n",
       "1          1.215054  \n",
       "2          1.215054  \n",
       "3          1.215054  \n",
       "4          1.172043  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_df = pd.read_csv('C:/Users/nafla/OneDrive/Documents/system development/training_data.csv')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     8.0\n",
      "0.50    24.0\n",
      "0.75    64.0\n",
      "Name: count, dtype: float64\n",
      "0.25     192.0\n",
      "0.50     552.5\n",
      "0.75    2539.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate quantiles for user activity and item popularity\n",
    "user_activity_quantiles = training_df['CustomerID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "item_popularity_quantiles = training_df['MovieID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "print(user_activity_quantiles)\n",
    "print(item_popularity_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['CustomerID'] = training_df['CustomerID'].astype(str)\n",
    "training_df['MovieID'] = training_df['MovieID'].astype(str)\n",
    "training_df['Rating'] = pd.to_numeric(training_df['Rating'], errors='coerce')  # Converts to float, makes non-numeric as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID                         object\n",
      "CustomerID                      object\n",
      "Rating                           int64\n",
      "Date                            object\n",
      "YearOfRelease                    int64\n",
      "MovieTitle                      object\n",
      "RatingYear                       int64\n",
      "MovieAge                         int64\n",
      "user_activity                  float64\n",
      "AverageMovieAgeRated           float64\n",
      "user_average_rating            float64\n",
      "average_rating_per_movie       float64\n",
      "number_of_ratings_per_movie    float64\n",
      "scaled_movie_age               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MovieID CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
      "0       1    1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
      "1       1     822109       5  2005-05-13           2003  Dinosaur Planet   \n",
      "2       1     885013       4  2005-10-19           2003  Dinosaur Planet   \n",
      "3       1      30878       4  2005-12-26           2003  Dinosaur Planet   \n",
      "4       1     823519       3  2004-05-03           2003  Dinosaur Planet   \n",
      "\n",
      "   RatingYear  MovieAge  user_activity  AverageMovieAgeRated  \\\n",
      "0        2005         2              1                     2   \n",
      "1        2005         2              1                     1   \n",
      "2        2005         2              1                     1   \n",
      "3        2005         2              1                     2   \n",
      "4        2004         1              1                     1   \n",
      "\n",
      "   user_average_rating  average_rating_per_movie  number_of_ratings_per_movie  \\\n",
      "0                    3                  3.910534                     1.010541   \n",
      "1                    4                  3.910534                     1.010541   \n",
      "2                    4                  3.910534                     1.010541   \n",
      "3                    4                  3.910534                     1.010541   \n",
      "4                    4                  3.910534                     1.010541   \n",
      "\n",
      "   scaled_movie_age  \n",
      "0          1.215054  \n",
      "1          1.215054  \n",
      "2          1.215054  \n",
      "3          1.215054  \n",
      "4          1.172043  \n"
     ]
    }
   ],
   "source": [
    "# List of your columns to be rounded and converted\n",
    "columns_to_round_and_convert = ['user_activity', 'AverageMovieAgeRated', 'user_average_rating']\n",
    "\n",
    "# Apply rounding and conversion to all specified columns\n",
    "for column in columns_to_round_and_convert:\n",
    "    training_df[column] = training_df[column].round().astype(int)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MovieID CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
      "0       1    1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
      "1       1     822109       5  2005-05-13           2003  Dinosaur Planet   \n",
      "2       1     885013       4  2005-10-19           2003  Dinosaur Planet   \n",
      "3       1      30878       4  2005-12-26           2003  Dinosaur Planet   \n",
      "4       1     823519       3  2004-05-03           2003  Dinosaur Planet   \n",
      "\n",
      "   RatingYear  user_activity  AverageMovieAgeRated  user_average_rating  \\\n",
      "0        2005              1                     2                    3   \n",
      "1        2005              1                     1                    4   \n",
      "2        2005              1                     1                    4   \n",
      "3        2005              1                     2                    4   \n",
      "4        2004              1                     1                    4   \n",
      "\n",
      "   scaled_movie_age  \n",
      "0          1.215054  \n",
      "1          1.215054  \n",
      "2          1.215054  \n",
      "3          1.215054  \n",
      "4          1.172043  \n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "# List the names of the columns you want to drop\n",
    "columns_to_drop = ['average_rating_per_movie', 'number_of_ratings_per_movie', 'MovieAge']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "training_df = training_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID                  object\n",
      "CustomerID               object\n",
      "Rating                    int64\n",
      "Date                     object\n",
      "YearOfRelease             int64\n",
      "MovieTitle               object\n",
      "RatingYear                int64\n",
      "user_activity             int32\n",
      "AverageMovieAgeRated      int32\n",
      "user_average_rating       int32\n",
      "scaled_movie_age        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in column 'column_name': 1\n",
      "Maximum value in column 'column_name': 5\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df and the column you're interested in is 'column_name'\n",
    "\n",
    "# Get the minimum value in the column\n",
    "min_value = training_df['user_average_rating'].min()\n",
    "\n",
    "# Get the maximum value in the column\n",
    "max_value = training_df['user_average_rating'].max()\n",
    "\n",
    "# Display the minimum and maximum values\n",
    "print(f\"Minimum value in column 'column_name': {min_value}\")\n",
    "print(f\"Maximum value in column 'column_name': {max_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampling Method \n",
    "\n",
    "To create a representative sample of our dataset, we employ a stratified sampling method that accounts for three key dimensions: Rating Distribution, User Activity, and Item Popularity. This approach ensures our sample maintains the diversity and characteristics of the entire dataset, facilitating more reliable model training and evaluation.\n",
    "\n",
    "- User Activity is quantified by the number of ratings a user has provided.\n",
    "- Item Popularity reflects the number of ratings an item has received.\n",
    "\n",
    "Finally, We combine User Activity, Item Popularity, and Rating into a composite stratification key for each record. This multi-dimensional key ensures our sampling process considers the distribution across all three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign each user and item to a bin based on the quantiles\n",
    "# training_df['UserActivityBin'] = pd.qcut(training_df.groupby('CustomerID')['Rating'].transform('size'), \n",
    "#                                 q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# # training_df['ItemPopularityBin'] = pd.qcut(training_df.groupby('MovieID')['Rating'].transform('size'), \n",
    "# #                                   q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# # Combine these with Rating to create a stratification key\n",
    "# # training_df['Strata'] = training_df['UserActivityBin'].astype(str) + \"_\" + training_df['ItemPopularityBin'].astype(str) + \"_\" + training_df['Rating'].astype(str)\n",
    "# training_df['Strata'] = training_df['UserActivityBin'].astype(str) + training_df['Rating'].astype(str)\n",
    "\n",
    "# # Perform stratified sampling\n",
    "# # we use groupby and  frac to specify a fraction of each strata and in case number of rows is less that 10 it takes all rows\n",
    "# strat_sample_df = training_df.groupby('Strata').apply(lambda x: x.sample(frac=0.005 if len(x) > 10 else len(x)/len(x))).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (24053575, 11)\n",
      "User-Filtered DataFrame shape: (23343305, 11)\n",
      "Movie-Filtered DataFrame shape: (23343305, 11)\n",
      "Sampled DataFrame shape: (116717, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'training_df' is your DataFrame\n",
    "\n",
    "# Step 1: Filter users with more than 10 ratings\n",
    "user_filtered_df = training_df.groupby('CustomerID').filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Step 2: Filter movies with more than 10 ratings\n",
    "movie_filtered_df = user_filtered_df.groupby('MovieID').filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Step 3: Perform random sampling\n",
    "# Replace 'fraction' with the fraction of data you want to sample. For example, 0.005 for 0.5%\n",
    "fraction = 0.005\n",
    "strat_sample_df = movie_filtered_df.sample(frac=fraction, random_state=42)  # Ensure reproducibility with random_state\n",
    "\n",
    "# Display the shapes of the original, user-filtered, movie-filtered, and sampled DataFrames\n",
    "print(\"Original DataFrame shape:\", training_df.shape)\n",
    "print(\"User-Filtered DataFrame shape:\", user_filtered_df.shape)\n",
    "print(\"Movie-Filtered DataFrame shape:\", movie_filtered_df.shape)\n",
    "print(\"Sampled DataFrame shape:\", strat_sample_df.shape)\n",
    "\n",
    "# 'strat_sample_df' now contains the randomly sampled data from both the users and movies with more than 10 ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the sampled DataFrame: 116717\n"
     ]
    }
   ],
   "source": [
    "num_sampled_rows = len(strat_sample_df)\n",
    "print(f\"Number of rows in the sampled DataFrame: {num_sampled_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset to training, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming strat_sample_df is your entire dataset\n",
    "user_ids = strat_sample_df['CustomerID'].unique()\n",
    "movie_ids = strat_sample_df['MovieID'].unique()\n",
    "\n",
    "# Create mappings based on the entire dataset\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "# Now, split your dataset\n",
    "training_data, testing_data = train_test_split(strat_sample_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids_to_indices(df, user_id_to_index, movie_id_to_index):\n",
    "    \"\"\"\n",
    "    Map user IDs and movie IDs to their respective indices.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing 'CustomerID', 'MovieID', and other columns.\n",
    "    - user_id_to_index: Dictionary mapping user IDs to indices.\n",
    "    - movie_id_to_index: Dictionary mapping movie IDs to indices.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with added columns 'UserIndex' and 'MovieIndex' for the respective indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    modified_data = df.copy()\n",
    "    \n",
    "    # Map 'CustomerID' to 'UserIndex'\n",
    "    modified_data['UserIndex'] = modified_data['CustomerID'].map(user_id_to_index)\n",
    "    \n",
    "    # Map 'MovieID' to 'MovieIndex'\n",
    "    modified_data['MovieIndex'] = modified_data['MovieID'].map(movie_id_to_index)\n",
    "    \n",
    "    # Optional: drop rows where either UserIndex or MovieIndex is NaN (i.e., ID wasn't found)\n",
    "    modified_data.dropna(subset=['UserIndex', 'MovieIndex'], inplace=True)\n",
    "    \n",
    "    # Convert indices to integers (they might be floats due to NaN handling)\n",
    "    modified_data['UserIndex'] = modified_data['UserIndex'].astype(int)\n",
    "    modified_data['MovieIndex'] = modified_data['MovieIndex'].astype(int)\n",
    "    \n",
    "    return modified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_training_data = map_ids_to_indices(training_data,user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 93373\n",
      "Training Data Size: 93373\n",
      "Testing Data Size: 23344\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of each split\n",
    "training_size = training_data.shape[0]  # Number of rows in the training data\n",
    "training_size_mapp = mapped_training_data.shape[0]  # Number of rows in the training data\n",
    "# validation_size = validation_data.shape[0]  # Number of rows in the validation data\n",
    "testing_size = testing_data.shape[0]  # Number of rows in the testing data\n",
    "\n",
    "# Print the sizes\n",
    "print(f\"Training Data Size: {training_size}\")\n",
    "print(f\"Training Data Size: {training_size_mapp}\")\n",
    "# print(f\"Validation Data Size: {validation_size}\")\n",
    "print(f\"Testing Data Size: {testing_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CustomerIDs in Training Data: 71886\n",
      "Unique MovieIDs in Testing Data: 21626\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_training_data, validation_data, and testing_data are your data splits\n",
    "\n",
    "# Count unique MovieIDs in the final training data\n",
    "unique_users_training = training_data['CustomerID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the validation data\n",
    "# unique_movies_validation = validation_data['MovieID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the testing data\n",
    "unique_movies_testing = testing_data['CustomerID'].nunique()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Unique CustomerIDs in Training Data: {unique_users_training}\")\n",
    "# print(f\"Unique MovieIDs in Validation Data: {unique_movies_validation}\")\n",
    "print(f\"Unique MovieIDs in Testing Data: {unique_movies_testing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating User - Item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customer-movie matrix\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# user_ids = training_data['CustomerID'].unique()\n",
    "# movie_ids = training_data['MovieID'].unique()\n",
    "\n",
    "# user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "# movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "\n",
    "# Extract rows, columns, and data for CSR matrix\n",
    "# rows = training_data['UserIndex'].values\n",
    "# cols = training_data['MovieIndex'].values\n",
    "# data = training_data['Rating'].values\n",
    "\n",
    "# # Calculate the shape of the matrix\n",
    "# num_users = len(user_id_to_index)\n",
    "# num_movies = len(movie_id_to_index)\n",
    "\n",
    "# # Create the CSR matrix\n",
    "# ratings_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))\n",
    "\n",
    "# print(ratings_csr_matrix)\n",
    "\n",
    "# # Extract the rows (user indices), columns (movie indices), and data (ratings) for the CSR matrix\n",
    "# rows = mapped_training_data['UserIndex'].values\n",
    "# cols = mapped_training_data['MovieIndex'].values\n",
    "# data = mapped_training_data['Rating'].values\n",
    "\n",
    "# # Determine the shape of the CSR matrix\n",
    "# # The shape is (max_user_index + 1, max_movie_index + 1) because indices start from 0\n",
    "# num_users = mapped_training_data['UserIndex'].max() + 1\n",
    "# num_movies = mapped_training_data['MovieIndex'].max() + 1\n",
    "\n",
    "# # Create the CSR matrix\n",
    "# ratings_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))\n",
    "\n",
    "# print(ratings_csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'mapped_training_data' is your training dataset that contains the features\n",
    "user_activity_values = mapped_training_data['user_activity'].values\n",
    "AverageMovieAgeRated_values = mapped_training_data['AverageMovieAgeRated'].values\n",
    "user_avg_rating_values = mapped_training_data['user_average_rating'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# Extract user indexes and movie indexes\n",
    "user_indexes = mapped_training_data['UserIndex'].values\n",
    "movie_indexes = mapped_training_data['MovieIndex'].values\n",
    "ratings = mapped_training_data['Rating'].values\n",
    "\n",
    "# Create the base user-item ratings CSR matrix\n",
    "num_users = user_indexes.max() + 1\n",
    "num_movies = movie_indexes.max() + 1\n",
    "ratings_csr_matrix = csr_matrix((ratings, (user_indexes, movie_indexes)), shape=(num_users, num_movies))\n",
    "\n",
    "# Create CSR matrices for features\n",
    "user_activity_matrix = csr_matrix((user_activity_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n",
    "avg_movie_age_matrix = csr_matrix((AverageMovieAgeRated_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n",
    "user_avg_rating_matrix = csr_matrix((user_avg_rating_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontally stack the features matrices with the ratings CSR matrix\n",
    "full_csr_matrix = hstack([ratings_csr_matrix, user_activity_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 240)\t3\n",
      "  (0, 356)\t1\n",
      "  (0, 903)\t5\n",
      "  (0, 3614)\t3\n",
      "  (1, 1)\t4\n",
      "  (1, 3614)\t1\n",
      "  (2, 2)\t3\n",
      "  (2, 246)\t4\n",
      "  (2, 1388)\t2\n",
      "  (2, 3614)\t6\n",
      "  (4, 4)\t4\n",
      "  (4, 3614)\t1\n",
      "  (5, 5)\t5\n",
      "  (5, 3614)\t1\n",
      "  (6, 6)\t5\n",
      "  (6, 7)\t2\n",
      "  (6, 14)\t5\n",
      "  (6, 40)\t4\n",
      "  (6, 692)\t5\n",
      "  (6, 3614)\t5\n",
      "  (7, 7)\t3\n",
      "  (7, 64)\t3\n",
      "  (7, 3614)\t2\n",
      "  (8, 8)\t5\n",
      "  (8, 3614)\t1\n",
      "  :\t:\n",
      "  (85063, 3614)\t1\n",
      "  (85064, 144)\t4\n",
      "  (85064, 3614)\t1\n",
      "  (85066, 479)\t5\n",
      "  (85066, 3614)\t1\n",
      "  (85067, 34)\t4\n",
      "  (85067, 3614)\t1\n",
      "  (85068, 219)\t4\n",
      "  (85068, 3614)\t1\n",
      "  (85070, 17)\t4\n",
      "  (85070, 3614)\t1\n",
      "  (85071, 802)\t5\n",
      "  (85071, 3614)\t1\n",
      "  (85073, 156)\t5\n",
      "  (85073, 3614)\t1\n",
      "  (85075, 83)\t3\n",
      "  (85075, 3614)\t1\n",
      "  (85078, 19)\t3\n",
      "  (85078, 3614)\t1\n",
      "  (85079, 131)\t5\n",
      "  (85079, 3614)\t1\n",
      "  (85080, 196)\t4\n",
      "  (85080, 3614)\t1\n",
      "  (85081, 623)\t1\n",
      "  (85081, 3614)\t1\n"
     ]
    }
   ],
   "source": [
    "print (full_csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define similarity function for each given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "cosine_similarity_matrix_csr = cosine_similarity(ratings_csr_matrix, dense_output=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82286)\t0.8451542547285166\n",
      "  (0, 79940)\t0.8451542547285166\n",
      "  (0, 68527)\t0.8451542547285166\n",
      "  (0, 66537)\t0.4610694459770735\n",
      "  (0, 55180)\t0.8451542547285166\n",
      "  (0, 51297)\t0.8451542547285166\n",
      "  (0, 44975)\t0.629940788348712\n",
      "  (0, 44222)\t0.8451542547285166\n",
      "  (0, 40900)\t0.8451542547285166\n",
      "  (0, 40221)\t0.8451542547285166\n",
      "  (0, 39531)\t0.7247137945655604\n",
      "  (0, 30346)\t0.6444240777830839\n",
      "  (0, 29624)\t0.8451542547285166\n",
      "  (0, 26182)\t0.8451542547285166\n",
      "  (0, 19897)\t0.8451542547285166\n",
      "  (0, 17360)\t0.8017837257372731\n",
      "  (0, 16537)\t0.8451542547285166\n",
      "  (0, 15146)\t0.8451542547285166\n",
      "  (0, 13565)\t0.8451542547285166\n",
      "  (0, 10008)\t0.4161251892882395\n",
      "  (0, 4155)\t0.7247137945655604\n",
      "  (0, 3970)\t0.8451542547285166\n",
      "  (0, 3598)\t0.8451542547285166\n",
      "  (0, 2775)\t0.8451542547285166\n",
      "  (0, 2563)\t0.5279636773484547\n",
      "  :\t:\n",
      "  (85081, 51054)\t1.0\n",
      "  (85081, 47513)\t0.7071067811865475\n",
      "  (85081, 47276)\t1.0\n",
      "  (85081, 44291)\t0.5144957554275265\n",
      "  (85081, 43971)\t1.0\n",
      "  (85081, 42291)\t0.3333333333333333\n",
      "  (85081, 41546)\t1.0\n",
      "  (85081, 41202)\t1.0\n",
      "  (85081, 40768)\t1.0\n",
      "  (85081, 38864)\t0.6246950475544243\n",
      "  (85081, 35445)\t0.7071067811865475\n",
      "  (85081, 35068)\t1.0\n",
      "  (85081, 34949)\t1.0\n",
      "  (85081, 31066)\t0.4472135954999579\n",
      "  (85081, 30000)\t0.4242640687119285\n",
      "  (85081, 29418)\t0.26967994498529685\n",
      "  (85081, 20517)\t1.0\n",
      "  (85081, 17495)\t1.0\n",
      "  (85081, 15868)\t0.7071067811865475\n",
      "  (85081, 15454)\t1.0\n",
      "  (85081, 13683)\t1.0\n",
      "  (85081, 11381)\t0.6666666666666666\n",
      "  (85081, 6856)\t0.6246950475544243\n",
      "  (85081, 5562)\t1.0\n",
      "  (85081, 798)\t0.3481553119113957\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85082, 85082)\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict ratings using similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given movie by a target user, based on the ratings of top-k similar users.\n",
    "    This function uses a pre-calculated similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix.\n",
    "    - similarity_matrix: CSR matrix representing the similarity scores between users.\n",
    "    - user_index: The index of the user for whom the rating is being predicted.\n",
    "    - movie_index: The index of the movie for which the rating is being predicted.\n",
    "    - k: Number of top similar users to consider for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted rating for the movie by the target user.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify users who have rated the movie\n",
    "    movie_rated_indices = csr_user_item_matrix[:, movie_index].nonzero()[0]\n",
    "    \n",
    "    # Check if user_index exists in the similarity matrix\n",
    "    if user_index < 0 or user_index >= similarity_matrix.shape[0]:\n",
    "        # If user_index does not exist in similarity matrix, return default prediction\n",
    "        overall_average_rating = csr_user_item_matrix[:, movie_index].data.mean()\n",
    "        return overall_average_rating if np.isfinite(overall_average_rating) else 3.0  # Assuming 3.0 as a neutral rating\n",
    "    \n",
    "    # Step 2: Extract similarity scores for the target user with all other users\n",
    "    user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "    \n",
    "    # Step 3: Filter the similarities for users who have rated the movie\n",
    "    filtered_similarities = user_similarities[movie_rated_indices]\n",
    "    \n",
    "    # Step 4: Get indices of top k similar users among those who have rated the movie\n",
    "    top_k_indices = np.argsort(filtered_similarities)[-k:]\n",
    "    top_k_users_indices = movie_rated_indices[top_k_indices]\n",
    "    top_k_similarities = filtered_similarities[top_k_indices]\n",
    "\n",
    "    # Retrieve ratings for the movie from these top-k similar users\n",
    "    top_k_ratings = csr_user_item_matrix[top_k_users_indices, movie_index].toarray().flatten()\n",
    "\n",
    "    # Calculate the weighted average rating\n",
    "    weighted_sum = np.dot(top_k_similarities, top_k_ratings)\n",
    "    similarity_sum = np.sum(top_k_similarities)\n",
    "    \n",
    "    if similarity_sum > 0:\n",
    "        predicted_rating = weighted_sum / similarity_sum\n",
    "    else:\n",
    "        # Use the overall average rating of the movie by all users as the default rating\n",
    "        overall_average_rating = csr_user_item_matrix[:, movie_index].data.mean()\n",
    "        predicted_rating = overall_average_rating if np.isfinite(overall_average_rating) else 3.0  # Assuming 3.0 as a neutral rating\n",
    "\n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def evaluate_predictions_csr(validation_data, csr_user_item_matrix, similarity_matrix, k):\n",
    "    \"\"\"\n",
    "    Evaluate the recommendation system by predicting ratings for each user-movie pair in the validation set\n",
    "    using a CSR matrix and pre-computed similarity matrix, and comparing the predictions to the actual ratings using RMSE.\n",
    "\n",
    "    Parameters:\n",
    "    - validation_data: DataFrame containing 'UserIndex', 'MovieIndex', and 'Rating'.\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix from the training set.\n",
    "    - similarity_matrix: Pre-computed similarity matrix as a CSR matrix.\n",
    "    - k: The number of top similar users to consider when making predictions.\n",
    "    \n",
    "    Returns:\n",
    "    - rmse: The root mean square error of the predicted ratings against the actual ratings.\n",
    "    \"\"\"\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "\n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_index = row['UserIndex']\n",
    "        movie_index = row['MovieIndex']\n",
    "        actual_rating = row['Rating']\n",
    "        \n",
    "        # Check if the movie index is valid\n",
    "        if movie_index in csr_user_item_matrix.indices:\n",
    "            predicted_rating = predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            actual_ratings.append(actual_rating)\n",
    "            predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    # Calculate RMSE between actual and predicted ratings\n",
    "    actual_ratings = np.array(actual_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "    valid_mask = ~np.isnan(predicted_ratings)\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings[valid_mask], predicted_ratings[valid_mask]))\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Average RMSE=0.9508280757776708\n",
      "k=50, Average RMSE=0.964437779735535\n",
      "k=200, Average RMSE=0.9678785252100521\n",
      "Best k: 5 with RMSE: 0.9508280757776708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Assuming k_values to test and your similarity matrix is already defined\n",
    "k_values = [5,  50,  200]\n",
    "similarity_matrix = cosine_similarity_matrix_csr\n",
    "# Setup KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    fold_rmses = []  # Store RMSEs for each fold\n",
    "\n",
    "    for train_indices, test_indices in kf.split(ratings_csr_matrix):\n",
    "        # Splitting your data: ratings_csr_matrix doesn't change, so you just map validation set indices\n",
    "        validation_data_fold = mapped_training_data.iloc[test_indices]\n",
    "\n",
    "        # Evaluate predictions on this fold's test set\n",
    "        rmse = evaluate_predictions_csr(validation_data_fold, ratings_csr_matrix, similarity_matrix, k)\n",
    "        fold_rmses.append(rmse)\n",
    "\n",
    "    # Calculate average RMSE for this k over all folds\n",
    "    avg_rmse = np.mean(fold_rmses)\n",
    "    results.append((k, avg_rmse))\n",
    "    print(f\"k={k}, Average RMSE={avg_rmse}\")\n",
    "\n",
    "# Find the best k value based on average RMSE\n",
    "best_k, best_rmse = min(results, key=lambda x: x[1])\n",
    "print(f\"Best k: {best_k} with RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_testing_data = map_ids_to_indices(testing_data, user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0653943639743557\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "similarity_matrix = cosine_similarity_matrix_csr\n",
    "k = 5  # Example value for k\n",
    "rmse = evaluate_predictions_csr(mapped_testing_data, ratings_csr_matrix, similarity_matrix, k)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_movies4(df, csr_user_item_matrix, similarity_matrix, user_ids, k, n):\n",
    "    \"\"\"\n",
    "    Recommend top n movies for specified user(s) based on predicted ratings.\n",
    "    Assumes 'UserIndex' and 'MovieIndex' are available in 'df'.\n",
    "    \"\"\"\n",
    "    if not isinstance(user_ids, list):\n",
    "        user_ids = [user_ids]\n",
    "\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            user_index = df[df['CustomerID'] == user_id]['UserIndex'].iloc[0]  # Assuming first matching UserIndex is representative\n",
    "        except IndexError:\n",
    "            print(f\"User ID {user_id} not found.\")\n",
    "            continue\n",
    "\n",
    "        unrated_movies_indices = np.setdiff1d(np.arange(csr_user_item_matrix.shape[1]),\n",
    "                                               csr_user_item_matrix.getrow(user_index).nonzero()[1])\n",
    "        \n",
    "        predicted_ratings = []\n",
    "        for movie_index in unrated_movies_indices:\n",
    "            predicted_rating = predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            movie_id = {v: k for k, v in movie_id_to_index.items()}[movie_index]  # Reverse lookup to get MovieID from MovieIndex\n",
    "            predicted_ratings.append((movie_id, predicted_rating))\n",
    "\n",
    "        top_n_recommendations = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:n]\n",
    "        recommendations[user_id] = top_n_recommendations\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_mapped_data = map_ids_to_indices(strat_sample_df, user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the rows (user indices), columns (movie indices), and data (ratings) for the CSR matrix\n",
    "rows = main_mapped_data['UserIndex'].values\n",
    "cols = main_mapped_data['MovieIndex'].values\n",
    "data = main_mapped_data['Rating'].values\n",
    "\n",
    "# Determine the shape of the CSR matrix\n",
    "# The shape is (max_user_index + 1, max_movie_index + 1) because indices start from 0\n",
    "num_users = main_mapped_data['UserIndex'].max() + 1\n",
    "num_movies = main_mapped_data['MovieIndex'].max() + 1\n",
    "\n",
    "# Create the CSR matrix\n",
    "Main_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_similarity_matrix = cosine_similarity(Main_csr_matrix, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85082, 85082)\n"
     ]
    }
   ],
   "source": [
    "print(main_similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>user_activity</th>\n",
       "      <th>AverageMovieAgeRated</th>\n",
       "      <th>user_average_rating</th>\n",
       "      <th>scaled_movie_age</th>\n",
       "      <th>UserIndex</th>\n",
       "      <th>MovieIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8464880</th>\n",
       "      <td>1693</td>\n",
       "      <td>1851346</td>\n",
       "      <td>1</td>\n",
       "      <td>2002-12-15</td>\n",
       "      <td>1998</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.301075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311316</th>\n",
       "      <td>1220</td>\n",
       "      <td>1710563</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-12-03</td>\n",
       "      <td>2004</td>\n",
       "      <td>Man on Fire</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.129032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17205447</th>\n",
       "      <td>3316</td>\n",
       "      <td>17864</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>2002</td>\n",
       "      <td>Bartleby</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.215054</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22300142</th>\n",
       "      <td>4227</td>\n",
       "      <td>1673744</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Full Monty</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.258065</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146126</th>\n",
       "      <td>1202</td>\n",
       "      <td>1321440</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>1983</td>\n",
       "      <td>National Lampoon's Vacation</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.032258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MovieID CustomerID  Rating        Date  YearOfRelease  \\\n",
       "8464880     1693    1851346       1  2002-12-15           1998   \n",
       "6311316     1220    1710563       4  2004-12-03           2004   \n",
       "17205447    3316      17864       3  2004-01-07           2002   \n",
       "22300142    4227    1673744       4  2000-02-26           1997   \n",
       "6146126     1202    1321440       4  2004-06-25           1983   \n",
       "\n",
       "                           MovieTitle  RatingYear  user_activity  \\\n",
       "8464880                        Sphere        2002              1   \n",
       "6311316                   Man on Fire        2004              1   \n",
       "17205447                     Bartleby        2004              2   \n",
       "22300142               The Full Monty        2000              1   \n",
       "6146126   National Lampoon's Vacation        2004              1   \n",
       "\n",
       "          AverageMovieAgeRated  user_average_rating  scaled_movie_age  \\\n",
       "8464880                      2                    3          1.301075   \n",
       "6311316                      2                    3          1.129032   \n",
       "17205447                     1                    3          1.215054   \n",
       "22300142                     2                    4          1.258065   \n",
       "6146126                      2                    4          2.032258   \n",
       "\n",
       "          UserIndex  MovieIndex  \n",
       "8464880           0           0  \n",
       "6311316           1           1  \n",
       "17205447          2           2  \n",
       "22300142          3           3  \n",
       "6146126           4           4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_mapped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User ID 1851346:\n",
      "\tMovie ID: 30, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 3122, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 1495, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 2780, Predicted Rating: 5.0\n",
      "\tMovie ID: 2342, Predicted Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have 'strat_sample_df', 'Main_csr_matrix', and 'main_similarity_matrix' prepared, along with 'user_id_to_index' and 'movie_id_to_index' mappings:\n",
    "\n",
    "user_ids = ['1851346']  # Single user example\n",
    "# user_ids = ['12345', '67890']  # Multiple users example\n",
    "k = 5  # Number of similar users to consider\n",
    "n = 5  # Number of recommendations to generate\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = recommend_movies4(main_mapped_data, Main_csr_matrix, main_similarity_matrix, user_ids, k, n)\n",
    "\n",
    "# Display the recommendations\n",
    "for user_id in user_ids:\n",
    "    print(f\"Recommendations for User ID {user_id}:\")\n",
    "    if user_id in recommendations:\n",
    "        for movie_id, predicted_rating in recommendations[user_id]:\n",
    "            print(f\"\\tMovie ID: {movie_id}, Predicted Rating: {predicted_rating}\")\n",
    "    else:\n",
    "        print(\"\\tNo recommendations available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def predict_rating_with_classification(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given movie by a target user, based on the ratings of top-k similar users using classification (voting) logic.\n",
    "    This function uses a pre-calculated similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix.\n",
    "    - similarity_matrix: CSR matrix representing the similarity scores between users.\n",
    "    - user_index: The index of the user for whom the rating is being predicted.\n",
    "    - movie_index: The index of the movie for which the rating is being predicted.\n",
    "    - k: Number of top similar users to consider for prediction.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted rating for the movie by the target user.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify users who have rated the movie\n",
    "    movie_rated_indices = csr_user_item_matrix[:, movie_index].nonzero()[0]\n",
    "    \n",
    "    # Check if user_index exists in the similarity matrix\n",
    "    if user_index < 0 or user_index >= similarity_matrix.shape[0]:\n",
    "        # If user_index does not exist in similarity matrix, return default prediction\n",
    "        non_zero_ratings = csr_user_item_matrix[:, movie_index][csr_user_item_matrix[movie_index] != 0]\n",
    "        predicted_rating = non_zero_ratings.mean() if len(non_zero_ratings) > 0 else np.nan # calculate average just concidering non zero ratings \n",
    "  \n",
    "    # Step 2: Extract similarity scores for the target user with all other users\n",
    "    user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "    \n",
    "    # Step 3: Filter the similarities for users who have rated the movie\n",
    "    filtered_similarities = user_similarities[movie_rated_indices]\n",
    "    \n",
    "    # Step 4: Get indices of top k similar users among those who have rated the movie\n",
    "    top_k_indices = np.argsort(filtered_similarities)[-k:]\n",
    "    top_k_users_indices = movie_rated_indices[top_k_indices]\n",
    "    top_k_similarities = filtered_similarities[top_k_indices]\n",
    "\n",
    "    # Retrieve ratings for the movie from these top-k similar users\n",
    "    top_k_ratings = csr_user_item_matrix[top_k_users_indices, movie_index].toarray().flatten()\n",
    "    \n",
    "    # Create a dictionary to hold the count of votes for each rating\n",
    "    rating_votes = defaultdict(int)\n",
    "    \n",
    "   # Calculate weights based on similarities and count votes for each rating\n",
    "    for similarity, rating in zip(top_k_similarities, top_k_ratings):\n",
    "        if rating in [1, 2, 3, 4, 5]:\n",
    "            rating_votes[rating] += similarity\n",
    "\n",
    "    # Find the rating with the highest sum of similarity weights\n",
    "    predicted_rating = max(rating_votes, key=rating_votes.get, default=np.nan)\n",
    "    \n",
    "    # Use the overall average rating of the movie by all users as the default rating\n",
    "    if np.isnan(predicted_rating):\n",
    "        non_zero_ratings = csr_user_item_matrix[:, movie_id][csr_user_item_matrix[movie_id] != 0]\n",
    "        predicted_rating = non_zero_ratings.mean() if len(non_zero_ratings) > 0 else np.nan # calculate average just concidering non zero ratings \n",
    "\n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User ID 1 and Movie ID 1000 is: 3 \n"
     ]
    }
   ],
   "source": [
    "user_index = 1  # Replace with actual user ID\n",
    "movie_index = 100  # Replace with actual movie ID\n",
    "K = 125  # Number of neighbors\n",
    "predicted_rating = predict_rating_with_classification (Main_csr_matrix, main_similarity_matrix, user_index, movie_index, k)\n",
    "print(f\"Predicted rating for User ID {user_id} and Movie ID {movie_id} is: {predicted_rating} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_movies_classification(df, csr_user_item_matrix, similarity_matrix, user_ids, k, n):\n",
    "    \"\"\"\n",
    "    Recommend top n movies for specified user(s) based on predicted ratings.\n",
    "    Assumes 'UserIndex' and 'MovieIndex' are available in 'df'.\n",
    "    \"\"\"\n",
    "    if not isinstance(user_ids, list):\n",
    "        user_ids = [user_ids]\n",
    "\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            user_index = df[df['CustomerID'] == user_id]['UserIndex'].iloc[0]  # Assuming first matching UserIndex is representative\n",
    "        except IndexError:\n",
    "            print(f\"User ID {user_id} not found.\")\n",
    "            continue\n",
    "\n",
    "        unrated_movies_indices = np.setdiff1d(np.arange(csr_user_item_matrix.shape[1]),\n",
    "                                               csr_user_item_matrix.getrow(user_index).nonzero()[1])\n",
    "        \n",
    "        predicted_ratings = []\n",
    "        for movie_index in unrated_movies_indices:\n",
    "            predicted_rating = predict_rating_with_classification(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            movie_id = {v: k for k, v in movie_id_to_index.items()}[movie_index]  # Reverse lookup to get MovieID from MovieIndex\n",
    "            predicted_ratings.append((movie_id, predicted_rating))\n",
    "\n",
    "        top_n_recommendations = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:n]\n",
    "        recommendations[user_id] = top_n_recommendations\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User ID 1851346:\n",
      "\tMovie ID: 2780, Predicted Rating: 5\n",
      "\tMovie ID: 2342, Predicted Rating: 5\n",
      "\tMovie ID: 3925, Predicted Rating: 5\n",
      "\tMovie ID: 2782, Predicted Rating: 5\n",
      "\tMovie ID: 1759, Predicted Rating: 5\n"
     ]
    }
   ],
   "source": [
    "user_ids = ['1851346']  # Single user example\n",
    "# user_ids = ['12345', '67890']  # Multiple users example\n",
    "k = 5  # Number of similar users to consider\n",
    "n = 5  # Number of recommendations to generate\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = recommend_movies_classification(main_mapped_data, Main_csr_matrix, main_similarity_matrix, user_ids, k, n)\n",
    "\n",
    "# Display the recommendations\n",
    "for user_id in user_ids:\n",
    "    print(f\"Recommendations for User ID {user_id}:\")\n",
    "    if user_id in recommendations:\n",
    "        for movie_id, predicted_rating in recommendations[user_id]:\n",
    "            print(f\"\\tMovie ID: {movie_id}, Predicted Rating: {predicted_rating}\")\n",
    "    else:\n",
    "        print(\"\\tNo recommendations available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
