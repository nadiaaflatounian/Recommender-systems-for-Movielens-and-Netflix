{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>MovieAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>2003</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  CustomerID  Rating        Date  YearOfRelease  RatingYear  \\\n",
       "0        1     1488844       3  2005-09-06           2003        2005   \n",
       "1        1      822109       5  2005-05-13           2003        2005   \n",
       "2        1      885013       4  2005-10-19           2003        2005   \n",
       "3        1       30878       4  2005-12-26           2003        2005   \n",
       "4        1      823519       3  2004-05-03           2003        2004   \n",
       "\n",
       "   MovieAge  \n",
       "0         2  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_df = pd.read_csv('C:/Users/nafla/OneDrive/Documents/system development/Netflix/training_data.csv')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     8.0\n",
      "0.50    24.0\n",
      "0.75    64.0\n",
      "Name: CustomerID, dtype: float64\n",
      "0.25     192.0\n",
      "0.50     552.5\n",
      "0.75    2539.0\n",
      "Name: MovieID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate quantiles for user activity and item popularity\n",
    "user_activity_quantiles = training_df['CustomerID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "item_popularity_quantiles = training_df['MovieID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "print(user_activity_quantiles)\n",
    "print(item_popularity_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['CustomerID'] = training_df['CustomerID'].astype(str)\n",
    "training_df['MovieID'] = training_df['MovieID'].astype(str)\n",
    "training_df['Rating'] = pd.to_numeric(training_df['Rating'], errors='coerce')  # Converts to float, makes non-numeric as NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampling Method \n",
    "\n",
    "To create a representative sample of our dataset, we employ a stratified sampling method that accounts for three key dimensions: Rating Distribution, User Activity, and Item Popularity. This approach ensures our sample maintains the diversity and characteristics of the entire dataset, facilitating more reliable model training and evaluation.\n",
    "\n",
    "- User Activity is quantified by the number of ratings a user has provided.\n",
    "- Item Popularity reflects the number of ratings an item has received.\n",
    "\n",
    "Finally, We combine User Activity, Item Popularity, and Rating into a composite stratification key for each record. This multi-dimensional key ensures our sampling process considers the distribution across all three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each user and item to a bin based on the quantiles\n",
    "training_df['UserActivityBin'] = pd.qcut(training_df.groupby('CustomerID')['Rating'].transform('size'), \n",
    "                                q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "training_df['ItemPopularityBin'] = pd.qcut(training_df.groupby('MovieID')['Rating'].transform('size'), \n",
    "                                  q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# Combine these with Rating to create a stratification key\n",
    "training_df['Strata'] = training_df['UserActivityBin'].astype(str) + \"_\" + training_df['ItemPopularityBin'].astype(str) + \"_\" + training_df['Rating'].astype(str)\n",
    "\n",
    "# Perform stratified sampling\n",
    "# we use groupby and  frac to specify a fraction of each strata and in case number of rows is less that 10 it takes all rows\n",
    "strat_sample_df = training_df.groupby('Strata').apply(lambda x: x.sample(frac=0.0001 if len(x) > 10 else len(x)/len(x))).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the sampled DataFrame: 2405\n"
     ]
    }
   ],
   "source": [
    "num_sampled_rows = len(strat_sample_df)\n",
    "print(f\"Number of rows in the sampled DataFrame: {num_sampled_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset to training, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming strat_sample_df is your dataframe and it has a 'CustomerID' column\n",
    "\n",
    "# Step 1: Group by 'CustomerID'\n",
    "groups = strat_sample_df.groupby('CustomerID')\n",
    "\n",
    "# Step 2: Split the grouped data into lists of groups for each dataset\n",
    "# Convert the GroupBy object to a list of (name, group) tuples\n",
    "groups = list(groups)\n",
    "\n",
    "# Shuffle the groups to randomize before splitting (optional, but recommended)\n",
    "import random\n",
    "random.seed(42)  # Ensure reproducibility\n",
    "random.shuffle(groups)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_groups = len(groups)\n",
    "training_size = int(total_groups * 0.6)\n",
    "validation_size = int(total_groups * 0.2)\n",
    "# Testing size is implied to be the rest\n",
    "\n",
    "# Split the groups\n",
    "training_groups = groups[:training_size]\n",
    "validation_groups = groups[training_size:(training_size + validation_size)]\n",
    "testing_groups = groups[(training_size + validation_size):]\n",
    "\n",
    "# Step 3: Concatenate the records within each split to form the final datasets\n",
    "training_data = pd.concat([group for _, group in training_groups])\n",
    "validation_data = pd.concat([group for _, group in validation_groups])\n",
    "testing_data = pd.concat([group for _, group in testing_groups])\n",
    "\n",
    "# Now you have training_data, validation_data, and testing_data with no CustomerID overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 1439\n",
      "Validation Data Size: 485\n",
      "Testing Data Size: 481\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of each split\n",
    "training_size = training_data.shape[0]  # Number of rows in the training data\n",
    "validation_size = validation_data.shape[0]  # Number of rows in the validation data\n",
    "testing_size = testing_data.shape[0]  # Number of rows in the testing data\n",
    "\n",
    "# Print the sizes\n",
    "print(f\"Training Data Size: {training_size}\")\n",
    "print(f\"Validation Data Size: {validation_size}\")\n",
    "print(f\"Testing Data Size: {testing_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customer-movie matrix\n",
    "user_item_matrix = training_data.pivot_table(index='CustomerID', columns='MovieID', values='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>10</th>\n",
       "      <th>1020</th>\n",
       "      <th>1026</th>\n",
       "      <th>1027</th>\n",
       "      <th>1035</th>\n",
       "      <th>104</th>\n",
       "      <th>1043</th>\n",
       "      <th>1046</th>\n",
       "      <th>1060</th>\n",
       "      <th>1061</th>\n",
       "      <th>...</th>\n",
       "      <th>962</th>\n",
       "      <th>963</th>\n",
       "      <th>964</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>980</th>\n",
       "      <th>983</th>\n",
       "      <th>985</th>\n",
       "      <th>989</th>\n",
       "      <th>990</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005657</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100864</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID     10  1020  1026  1027  1035  104  1043  1046  1060  1061  ...  962  \\\n",
       "CustomerID                                                           ...        \n",
       "10007      NaN   NaN   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN  ...  NaN   \n",
       "1004258    NaN   NaN   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN  ...  NaN   \n",
       "1005657    NaN   NaN   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN  ...  NaN   \n",
       "1006457    NaN   NaN   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN  ...  NaN   \n",
       "100864     NaN   NaN   NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN  ...  NaN   \n",
       "\n",
       "MovieID     963  964  97  98  980  983  985  989  990  \n",
       "CustomerID                                             \n",
       "10007       NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1004258     NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1005657     NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1006457     NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "100864      NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 653 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_cosine_similarity(target_vector, other_vector):\n",
    "    # Mask for common non-NaN ratings\n",
    "    common_mask = ~np.isnan(target_vector) & ~np.isnan(other_vector)\n",
    "    if not np.any(common_mask):\n",
    "        return 0  # No common ratings\n",
    "    \n",
    "    # Extracting common ratings\n",
    "    target_common = target_vector[common_mask]\n",
    "    other_common = other_vector[common_mask]\n",
    "    \n",
    "    # Compute dot product and norms of common ratings\n",
    "    dot_product = np.dot(target_common, other_common)\n",
    "    target_norm = np.linalg.norm(target_common)\n",
    "    other_norm = np.linalg.norm(other_common)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    if target_norm == 0 or other_norm == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    similarity = dot_product / (target_norm * other_norm)\n",
    "    return similarity\n",
    "\n",
    "def calculate_all_similarities(user_item_matrix, user_id):\n",
    "    # Ensure we're working with raw values for manual handling\n",
    "    matrix_values = user_item_matrix.values\n",
    "    user_index = user_item_matrix.index.get_loc(user_id)\n",
    "    target_user_ratings = matrix_values[user_index, :]\n",
    "    \n",
    "    similarities = []\n",
    "    for i, other_user_ratings in enumerate(matrix_values):\n",
    "        if i == user_index:\n",
    "            continue  # Skip comparing user to themselves\n",
    "        similarity = custom_cosine_similarity(target_user_ratings, other_user_ratings)\n",
    "        if similarity != 0:  # Collect non-zero similarities\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    return similarities if similarities else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "user_id = '1005657'\n",
    "similarities = calculate_all_similarities(user_item_matrix, user_id)\n",
    "\n",
    "# Print or process the similarities as needed\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_pearson_similarity(user_item_matrix, target_user_id):\n",
    "    # Ensure target_user_id is in the index to avoid key errors\n",
    "    if target_user_id not in user_item_matrix.index:\n",
    "        return \"Target user ID not found in the user-item matrix.\"\n",
    "    \n",
    "    target_ratings = user_item_matrix.loc[target_user_id].values\n",
    "    similarities = {}\n",
    "\n",
    "    for user_id in user_item_matrix.index:\n",
    "        if user_id == target_user_id:\n",
    "            continue  # Skip similarity with the user themselves\n",
    "\n",
    "        user_ratings = user_item_matrix.loc[user_id].values\n",
    "        \n",
    "        # Mask to select only common non-NaN ratings between the target user and the current user\n",
    "        common_mask = ~np.isnan(target_ratings) & ~np.isnan(user_ratings)\n",
    "        \n",
    "        if np.sum(common_mask) < 2:  # Ensure there are at least two common ratings\n",
    "            continue  # Skip this pair if not enough common ratings\n",
    "        \n",
    "        # Calculate Pearson correlation coefficient for common non-NaN ratings\n",
    "        correlation, _ = pearsonr(target_ratings[common_mask], user_ratings[common_mask])\n",
    "        \n",
    "        # Store the correlation if it's a valid number\n",
    "        if np.isfinite(correlation):\n",
    "            similarities[user_id] = correlation\n",
    "            \n",
    "    return similarities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "# Assuming user_item_matrix is your DataFrame with 'CustomerID' as index\n",
    "# and 'MovieID' as columns, and 'Rating' as values\n",
    "target_user_id = '100864' # replace <specific_user_id> with an actual CustomerID\n",
    "similarities = calculate_pearson_similarity(user_item_matrix, target_user_id)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_manhattan_similarity(user_item_matrix, target_user_id):\n",
    "    \"\"\"\n",
    "    Calculate user similarities using Manhattan distance.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_item_matrix: A DataFrame where rows are users, columns are items, and values are ratings.\n",
    "    - target_user_id: The user ID for which to calculate similarities.\n",
    "    \n",
    "    Returns:\n",
    "    A Series with user IDs as the index and the similarity scores as the values.\n",
    "    \"\"\"\n",
    "    # Ensure target_user_id is a string, matching the user IDs in your user_item_matrix index\n",
    "    target_user_id = str(target_user_id)\n",
    "    \n",
    "    # Check if the target_user_id exists in the user_item_matrix\n",
    "    if target_user_id not in user_item_matrix.index:\n",
    "        return \"Target user ID not found in the user-item matrix.\"\n",
    "    \n",
    "    # Retrieve the target user's ratings\n",
    "    target_user_ratings = user_item_matrix.loc[target_user_id]\n",
    "    \n",
    "    # Initialize a dictionary to store the similarity scores\n",
    "    similarities = {}\n",
    "    \n",
    "    # Iterate over all users in the matrix to compute Manhattan distance to the target user\n",
    "    for user_id in user_item_matrix.index:\n",
    "        if user_id == target_user_id:\n",
    "            continue  # Skip the target user\n",
    "        \n",
    "        # Compute the Manhattan distance\n",
    "        user_ratings = user_item_matrix.loc[user_id]\n",
    "        distance = np.nansum(np.abs(target_user_ratings - user_ratings))\n",
    "        \n",
    "        # Convert distance to similarity, avoiding division by zero\n",
    "        similarity = 1 / (1 + distance) if distance != 0 else 0\n",
    "        similarities[user_id] = similarity\n",
    "    \n",
    "    # Convert the similarities dictionary to a pandas Series for easy handling and return\n",
    "    similarity_series = pd.Series(similarities, name=\"Similarity\")\n",
    "    \n",
    "    return similarity_series.sort_values(ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2519568    0.333333\n",
      "10007      0.000000\n",
      "257913     0.000000\n",
      "2587797    0.000000\n",
      "2587481    0.000000\n",
      "             ...   \n",
      "1792108    0.000000\n",
      "1791361    0.000000\n",
      "1791124    0.000000\n",
      "1790119    0.000000\n",
      "99865      0.000000\n",
      "Name: Similarity, Length: 1428, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "target_user_id = '100864'  # Replace with the actual CustomerID as a string\n",
    "similarities = calculate_manhattan_similarity(user_item_matrix, target_user_id)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_rating(user_item_matrix, target_user_id, movie_id, k, similarity_method):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given movie by a target user, based on the ratings of top-k similar users.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_item_matrix: DataFrame with users as rows, movies as columns, and ratings as values.\n",
    "    - target_user_id: The ID of the user for whom the rating is being predicted.\n",
    "    - movie_id: The ID of the movie for which the rating is being predicted.\n",
    "    - k: Number of top similar users to consider for prediction.\n",
    "    - similarity_method: Function to calculate similarity scores between users.\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted rating for the movie by the target user.\n",
    "    \"\"\"\n",
    "    # Calculate similarity scores between the target user and all others\n",
    "    similarities = similarity_method(user_item_matrix, target_user_id)\n",
    "    \n",
    "    # Filter top-k similar users\n",
    "    top_k_users = similarities.nlargest(k+1).drop(target_user_id, errors='ignore').index\n",
    "    \n",
    "    # Check if the movie has been rated by top-k users\n",
    "    top_k_ratings = user_item_matrix.loc[top_k_users, movie_id]\n",
    "    top_k_similarities = similarities[top_k_users]\n",
    "    \n",
    "    # Calculate weighted average rating\n",
    "    if not top_k_ratings.isnull().all():\n",
    "        weighted_ratings = top_k_ratings * top_k_similarities\n",
    "        predicted_rating = weighted_ratings.sum() / top_k_similarities[top_k_ratings.notnull()].sum()\n",
    "    else:\n",
    "        # Use the average rating for the movie if available\n",
    "        if user_item_matrix[movie_id].notnull().any():\n",
    "            predicted_rating = user_item_matrix[movie_id].mean()\n",
    "        else:\n",
    "            # Default rating if the movie has not been rated by anyone\n",
    "            predicted_rating = 3\n",
    "            \n",
    "    return predicted_rating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Ensure you've defined a similarity method like calculate_manhattan_similarity, calculate_pearson_similarity, etc.\n",
    "target_user_id = '100864'  # replace with actual user ID as a string\n",
    "movie_id = '1020'  # replace with actual movie ID\n",
    "k = 5  # Number of top similar users to consider\n",
    "predicted_rating = predict_rating(user_item_matrix, target_user_id, movie_id, k, calculate_manhattan_similarity)  # Replace similarity method as needed\n",
    "print(f\"Predicted Rating: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def evaluate_recommender(user_item_matrix, validation_data, k, similarity_method):\n",
    "    \"\"\"\n",
    "    Evaluate the recommender system by calculating RMSE on the validation dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_item_matrix: DataFrame with users as rows, movies as columns, and ratings as values (training data).\n",
    "    - validation_data: DataFrame with columns ['CustomerID', 'MovieID', 'Rating'] for validation.\n",
    "    - k: Number of top similar users to consider for predicting ratings.\n",
    "    - similarity_method: Function to calculate similarity scores between users.\n",
    "    \n",
    "    Returns:\n",
    "    - rmse: The root mean square error of the predicted ratings against the actual ratings in the validation dataset.\n",
    "    \"\"\"\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for index, row in validation_data.iterrows():\n",
    "        user_id, movie_id, actual_rating = row['CustomerID'], row['MovieID'], row['Rating']\n",
    "        predicted_rating = predict_rating(user_item_matrix, user_id, movie_id, k, similarity_method)\n",
    "        \n",
    "        actual_ratings.append(actual_rating)\n",
    "        predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    return rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'nlargest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# and you have a similarity method like calculate_manhattan_similarity or any other defined.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of top similar users to consider\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_recommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_manhattan_similarity\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace similarity method as needed\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[68], line 22\u001b[0m, in \u001b[0;36mevaluate_recommender\u001b[1;34m(user_item_matrix, validation_data, k, similarity_method)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m validation_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     21\u001b[0m     user_id, movie_id, actual_rating \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovieID\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m     predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     actual_ratings\u001b[38;5;241m.\u001b[39mappend(actual_rating)\n\u001b[0;32m     25\u001b[0m     predicted_ratings\u001b[38;5;241m.\u001b[39mappend(predicted_rating)\n",
      "Cell \u001b[1;32mIn[61], line 22\u001b[0m, in \u001b[0;36mpredict_rating\u001b[1;34m(user_item_matrix, target_user_id, movie_id, k, similarity_method)\u001b[0m\n\u001b[0;32m     19\u001b[0m similarities \u001b[38;5;241m=\u001b[39m similarity_method(user_item_matrix, target_user_id)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Filter top-k similar users\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m top_k_users \u001b[38;5;241m=\u001b[39m \u001b[43msimilarities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m(k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(target_user_id, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Check if the movie has been rated by top-k users\u001b[39;00m\n\u001b[0;32m     25\u001b[0m top_k_ratings \u001b[38;5;241m=\u001b[39m user_item_matrix\u001b[38;5;241m.\u001b[39mloc[top_k_users, movie_id]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'nlargest'"
     ]
    }
   ],
   "source": [
    "# Example usage:.\n",
    "k = 5  # Number of top similar users to consider\n",
    "rmse = evaluate_recommender(user_item_matrix, validation_data, k, calculate_manhattan_similarity)  # Replace similarity method as needed\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
