{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>MovieAge</th>\n",
       "      <th>user_activity</th>\n",
       "      <th>AverageMovieAgeRated</th>\n",
       "      <th>user_average_rating</th>\n",
       "      <th>average_rating_per_movie</th>\n",
       "      <th>number_of_ratings_per_movie</th>\n",
       "      <th>scaled_movie_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.473012</td>\n",
       "      <td>1.640503</td>\n",
       "      <td>3.253308</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.031355</td>\n",
       "      <td>1.405855</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.077044</td>\n",
       "      <td>1.400853</td>\n",
       "      <td>3.873563</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>1.275924</td>\n",
       "      <td>1.525706</td>\n",
       "      <td>3.634304</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.215054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1.139754</td>\n",
       "      <td>1.326786</td>\n",
       "      <td>3.917197</td>\n",
       "      <td>3.910534</td>\n",
       "      <td>1.010541</td>\n",
       "      <td>1.172043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
       "0        1     1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
       "1        1      822109       5  2005-05-13           2003  Dinosaur Planet   \n",
       "2        1      885013       4  2005-10-19           2003  Dinosaur Planet   \n",
       "3        1       30878       4  2005-12-26           2003  Dinosaur Planet   \n",
       "4        1      823519       3  2004-05-03           2003  Dinosaur Planet   \n",
       "\n",
       "   RatingYear  MovieAge  user_activity  AverageMovieAgeRated  \\\n",
       "0        2005         2       1.473012              1.640503   \n",
       "1        2005         2       1.031355              1.405855   \n",
       "2        2005         2       1.077044              1.400853   \n",
       "3        2005         2       1.275924              1.525706   \n",
       "4        2004         1       1.139754              1.326786   \n",
       "\n",
       "   user_average_rating  average_rating_per_movie  number_of_ratings_per_movie  \\\n",
       "0             3.253308                  3.910534                     1.010541   \n",
       "1             4.083333                  3.910534                     1.010541   \n",
       "2             3.873563                  3.910534                     1.010541   \n",
       "3             3.634304                  3.910534                     1.010541   \n",
       "4             3.917197                  3.910534                     1.010541   \n",
       "\n",
       "   scaled_movie_age  \n",
       "0          1.215054  \n",
       "1          1.215054  \n",
       "2          1.215054  \n",
       "3          1.215054  \n",
       "4          1.172043  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_df = pd.read_csv('C:/Users/nafla/OneDrive/Documents/system development/training_data.csv')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     8.0\n",
      "0.50    24.0\n",
      "0.75    64.0\n",
      "Name: count, dtype: float64\n",
      "0.25     192.0\n",
      "0.50     552.5\n",
      "0.75    2539.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate quantiles for user activity and item popularity\n",
    "user_activity_quantiles = training_df['CustomerID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "item_popularity_quantiles = training_df['MovieID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "print(user_activity_quantiles)\n",
    "print(item_popularity_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['CustomerID'] = training_df['CustomerID'].astype(str)\n",
    "training_df['MovieID'] = training_df['MovieID'].astype(str)\n",
    "training_df['Rating'] = pd.to_numeric(training_df['Rating'], errors='coerce')  # Converts to float, makes non-numeric as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion:\n",
      "MovieID                         object\n",
      "CustomerID                      object\n",
      "Rating                           int64\n",
      "Date                            object\n",
      "YearOfRelease                    int64\n",
      "MovieTitle                      object\n",
      "RatingYear                       int64\n",
      "MovieAge                         int64\n",
      "user_activity                  float64\n",
      "AverageMovieAgeRated           float64\n",
      "user_average_rating            float64\n",
      "average_rating_per_movie       float64\n",
      "number_of_ratings_per_movie    float64\n",
      "scaled_movie_age               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MovieID CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
      "0       1    1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
      "1       1     822109       5  2005-05-13           2003  Dinosaur Planet   \n",
      "2       1     885013       4  2005-10-19           2003  Dinosaur Planet   \n",
      "3       1      30878       4  2005-12-26           2003  Dinosaur Planet   \n",
      "4       1     823519       3  2004-05-03           2003  Dinosaur Planet   \n",
      "\n",
      "   RatingYear  MovieAge  user_activity  AverageMovieAgeRated  \\\n",
      "0        2005         2              1                     2   \n",
      "1        2005         2              1                     1   \n",
      "2        2005         2              1                     1   \n",
      "3        2005         2              1                     2   \n",
      "4        2004         1              1                     1   \n",
      "\n",
      "   user_average_rating  average_rating_per_movie  number_of_ratings_per_movie  \\\n",
      "0                    3                  3.910534                     1.010541   \n",
      "1                    4                  3.910534                     1.010541   \n",
      "2                    4                  3.910534                     1.010541   \n",
      "3                    4                  3.910534                     1.010541   \n",
      "4                    4                  3.910534                     1.010541   \n",
      "\n",
      "   scaled_movie_age UserActivityBin        Strata  \n",
      "0          1.215054            high         high3  \n",
      "1          1.215054             low          low5  \n",
      "2          1.215054          medium       medium4  \n",
      "3          1.215054            high         high4  \n",
      "4          1.172043     medium-high  medium-high3  \n"
     ]
    }
   ],
   "source": [
    "# List of your columns to be rounded and converted\n",
    "columns_to_round_and_convert = ['user_activity', 'AverageMovieAgeRated', 'user_average_rating']\n",
    "\n",
    "# Apply rounding and conversion to all specified columns\n",
    "for column in columns_to_round_and_convert:\n",
    "    training_df[column] = training_df[column].round().astype(int)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MovieID CustomerID  Rating        Date  YearOfRelease       MovieTitle  \\\n",
      "0       1    1488844       3  2005-09-06           2003  Dinosaur Planet   \n",
      "1       1     822109       5  2005-05-13           2003  Dinosaur Planet   \n",
      "2       1     885013       4  2005-10-19           2003  Dinosaur Planet   \n",
      "3       1      30878       4  2005-12-26           2003  Dinosaur Planet   \n",
      "4       1     823519       3  2004-05-03           2003  Dinosaur Planet   \n",
      "\n",
      "   RatingYear  user_activity  AverageMovieAgeRated  user_average_rating  \\\n",
      "0        2005              1                     2                    3   \n",
      "1        2005              1                     1                    4   \n",
      "2        2005              1                     1                    4   \n",
      "3        2005              1                     2                    4   \n",
      "4        2004              1                     1                    4   \n",
      "\n",
      "   scaled_movie_age UserActivityBin        Strata  \n",
      "0          1.215054            high         high3  \n",
      "1          1.215054             low          low5  \n",
      "2          1.215054          medium       medium4  \n",
      "3          1.215054            high         high4  \n",
      "4          1.172043     medium-high  medium-high3  \n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "# List the names of the columns you want to drop\n",
    "columns_to_drop = ['average_rating_per_movie', 'number_of_ratings_per_movie', 'MovieAge']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "training_df = training_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID                   object\n",
      "CustomerID                object\n",
      "Rating                     int64\n",
      "Date                      object\n",
      "YearOfRelease              int64\n",
      "MovieTitle                object\n",
      "RatingYear                 int64\n",
      "user_activity              int32\n",
      "AverageMovieAgeRated       int32\n",
      "user_average_rating        int32\n",
      "scaled_movie_age         float64\n",
      "UserActivityBin         category\n",
      "Strata                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in column 'column_name': 1\n",
      "Maximum value in column 'column_name': 5\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df and the column you're interested in is 'column_name'\n",
    "\n",
    "# Get the minimum value in the column\n",
    "min_value = training_df['user_average_rating'].min()\n",
    "\n",
    "# Get the maximum value in the column\n",
    "max_value = training_df['user_average_rating'].max()\n",
    "\n",
    "# Display the minimum and maximum values\n",
    "print(f\"Minimum value in column 'column_name': {min_value}\")\n",
    "print(f\"Maximum value in column 'column_name': {max_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampling Method \n",
    "\n",
    "To create a representative sample of our dataset, we employ a stratified sampling method that accounts for three key dimensions: Rating Distribution, User Activity, and Item Popularity. This approach ensures our sample maintains the diversity and characteristics of the entire dataset, facilitating more reliable model training and evaluation.\n",
    "\n",
    "- User Activity is quantified by the number of ratings a user has provided.\n",
    "- Item Popularity reflects the number of ratings an item has received.\n",
    "\n",
    "Finally, We combine User Activity, Item Popularity, and Rating into a composite stratification key for each record. This multi-dimensional key ensures our sampling process considers the distribution across all three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign each user and item to a bin based on the quantiles\n",
    "# training_df['UserActivityBin'] = pd.qcut(training_df.groupby('CustomerID')['Rating'].transform('size'), \n",
    "#                                 q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# # training_df['ItemPopularityBin'] = pd.qcut(training_df.groupby('MovieID')['Rating'].transform('size'), \n",
    "# #                                   q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# # Combine these with Rating to create a stratification key\n",
    "# # training_df['Strata'] = training_df['UserActivityBin'].astype(str) + \"_\" + training_df['ItemPopularityBin'].astype(str) + \"_\" + training_df['Rating'].astype(str)\n",
    "# training_df['Strata'] = training_df['UserActivityBin'].astype(str) + training_df['Rating'].astype(str)\n",
    "\n",
    "# # Perform stratified sampling\n",
    "# # we use groupby and  frac to specify a fraction of each strata and in case number of rows is less that 10 it takes all rows\n",
    "# strat_sample_df = training_df.groupby('Strata').apply(lambda x: x.sample(frac=0.005 if len(x) > 10 else len(x)/len(x))).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (24053575, 13)\n",
      "User-Filtered DataFrame shape: (23343305, 13)\n",
      "Movie-Filtered DataFrame shape: (23343305, 13)\n",
      "Sampled DataFrame shape: (116717, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'training_df' is your DataFrame\n",
    "\n",
    "# Step 1: Filter users with more than 10 ratings\n",
    "user_filtered_df = training_df.groupby('CustomerID').filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Step 2: Filter movies with more than 10 ratings\n",
    "movie_filtered_df = user_filtered_df.groupby('MovieID').filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Step 3: Perform random sampling\n",
    "# Replace 'fraction' with the fraction of data you want to sample. For example, 0.005 for 0.5%\n",
    "fraction = 0.005\n",
    "strat_sample_df = movie_filtered_df.sample(frac=fraction, random_state=42)  # Ensure reproducibility with random_state\n",
    "\n",
    "# Display the shapes of the original, user-filtered, movie-filtered, and sampled DataFrames\n",
    "print(\"Original DataFrame shape:\", training_df.shape)\n",
    "print(\"User-Filtered DataFrame shape:\", user_filtered_df.shape)\n",
    "print(\"Movie-Filtered DataFrame shape:\", movie_filtered_df.shape)\n",
    "print(\"Sampled DataFrame shape:\", strat_sample_df.shape)\n",
    "\n",
    "# 'strat_sample_df' now contains the randomly sampled data from both the users and movies with more than 10 ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the sampled DataFrame: 116717\n"
     ]
    }
   ],
   "source": [
    "num_sampled_rows = len(strat_sample_df)\n",
    "print(f\"Number of rows in the sampled DataFrame: {num_sampled_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset to training, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming strat_sample_df is your entire dataset\n",
    "user_ids = strat_sample_df['CustomerID'].unique()\n",
    "movie_ids = strat_sample_df['MovieID'].unique()\n",
    "\n",
    "# Create mappings based on the entire dataset\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "# Now, split your dataset\n",
    "training_data, testing_data = train_test_split(strat_sample_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids_to_indices(df, user_id_to_index, movie_id_to_index):\n",
    "    \"\"\"\n",
    "    Map user IDs and movie IDs to their respective indices.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing 'CustomerID', 'MovieID', and other columns.\n",
    "    - user_id_to_index: Dictionary mapping user IDs to indices.\n",
    "    - movie_id_to_index: Dictionary mapping movie IDs to indices.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with added columns 'UserIndex' and 'MovieIndex' for the respective indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    modified_data = df.copy()\n",
    "    \n",
    "    # Map 'CustomerID' to 'UserIndex'\n",
    "    modified_data['UserIndex'] = modified_data['CustomerID'].map(user_id_to_index)\n",
    "    \n",
    "    # Map 'MovieID' to 'MovieIndex'\n",
    "    modified_data['MovieIndex'] = modified_data['MovieID'].map(movie_id_to_index)\n",
    "    \n",
    "    # Optional: drop rows where either UserIndex or MovieIndex is NaN (i.e., ID wasn't found)\n",
    "    modified_data.dropna(subset=['UserIndex', 'MovieIndex'], inplace=True)\n",
    "    \n",
    "    # Convert indices to integers (they might be floats due to NaN handling)\n",
    "    modified_data['UserIndex'] = modified_data['UserIndex'].astype(int)\n",
    "    modified_data['MovieIndex'] = modified_data['MovieIndex'].astype(int)\n",
    "    \n",
    "    return modified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_training_data = map_ids_to_indices(training_data,user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 93373\n",
      "Training Data Size: 93373\n",
      "Testing Data Size: 23344\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of each split\n",
    "training_size = training_data.shape[0]  # Number of rows in the training data\n",
    "training_size_mapp = mapped_training_data.shape[0]  # Number of rows in the training data\n",
    "# validation_size = validation_data.shape[0]  # Number of rows in the validation data\n",
    "testing_size = testing_data.shape[0]  # Number of rows in the testing data\n",
    "\n",
    "# Print the sizes\n",
    "print(f\"Training Data Size: {training_size}\")\n",
    "print(f\"Training Data Size: {training_size_mapp}\")\n",
    "# print(f\"Validation Data Size: {validation_size}\")\n",
    "print(f\"Testing Data Size: {testing_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CustomerIDs in Training Data: 71886\n",
      "Unique MovieIDs in Testing Data: 21626\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_training_data, validation_data, and testing_data are your data splits\n",
    "\n",
    "# Count unique MovieIDs in the final training data\n",
    "unique_users_training = training_data['CustomerID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the validation data\n",
    "# unique_movies_validation = validation_data['MovieID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the testing data\n",
    "unique_movies_testing = testing_data['CustomerID'].nunique()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Unique CustomerIDs in Training Data: {unique_users_training}\")\n",
    "# print(f\"Unique MovieIDs in Validation Data: {unique_movies_validation}\")\n",
    "print(f\"Unique MovieIDs in Testing Data: {unique_movies_testing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating User - Item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating customer-movie matrix\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# user_ids = training_data['CustomerID'].unique()\n",
    "# movie_ids = training_data['MovieID'].unique()\n",
    "\n",
    "# user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "# movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "\n",
    "# Extract rows, columns, and data for CSR matrix\n",
    "# rows = training_data['UserIndex'].values\n",
    "# cols = training_data['MovieIndex'].values\n",
    "# data = training_data['Rating'].values\n",
    "\n",
    "# # Calculate the shape of the matrix\n",
    "# num_users = len(user_id_to_index)\n",
    "# num_movies = len(movie_id_to_index)\n",
    "\n",
    "# # Create the CSR matrix\n",
    "# ratings_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))\n",
    "\n",
    "# print(ratings_csr_matrix)\n",
    "\n",
    "# # Extract the rows (user indices), columns (movie indices), and data (ratings) for the CSR matrix\n",
    "# rows = mapped_training_data['UserIndex'].values\n",
    "# cols = mapped_training_data['MovieIndex'].values\n",
    "# data = mapped_training_data['Rating'].values\n",
    "\n",
    "# # Determine the shape of the CSR matrix\n",
    "# # The shape is (max_user_index + 1, max_movie_index + 1) because indices start from 0\n",
    "# num_users = mapped_training_data['UserIndex'].max() + 1\n",
    "# num_movies = mapped_training_data['MovieIndex'].max() + 1\n",
    "\n",
    "# # Create the CSR matrix\n",
    "# ratings_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))\n",
    "\n",
    "# print(ratings_csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'mapped_training_data' is your training dataset that contains the features\n",
    "user_activity_values = mapped_training_data['user_activity'].values\n",
    "AverageMovieAgeRated_values = mapped_training_data['AverageMovieAgeRated'].values\n",
    "user_avg_rating_values = mapped_training_data['user_average_rating'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# Extract user indexes and movie indexes\n",
    "user_indexes = mapped_training_data['UserIndex'].values\n",
    "movie_indexes = mapped_training_data['MovieIndex'].values\n",
    "ratings = mapped_training_data['Rating'].values\n",
    "\n",
    "# Create the base user-item ratings CSR matrix\n",
    "num_users = user_indexes.max() + 1\n",
    "num_movies = movie_indexes.max() + 1\n",
    "ratings_csr_matrix = csr_matrix((ratings, (user_indexes, movie_indexes)), shape=(num_users, num_movies))\n",
    "\n",
    "# Create CSR matrices for features\n",
    "user_activity_matrix = csr_matrix((user_activity_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n",
    "avg_movie_age_matrix = csr_matrix((AverageMovieAgeRated_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n",
    "user_avg_rating_matrix = csr_matrix((user_avg_rating_values, (user_indexes, np.zeros_like(user_indexes))), shape=(num_users, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontally stack the features matrices with the ratings CSR matrix\n",
    "full_csr_matrix = hstack([ratings_csr_matrix, user_activity_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 240)\t3\n",
      "  (0, 356)\t1\n",
      "  (0, 903)\t5\n",
      "  (0, 3614)\t3\n",
      "  (1, 1)\t4\n",
      "  (1, 3614)\t1\n",
      "  (2, 2)\t3\n",
      "  (2, 246)\t4\n",
      "  (2, 1388)\t2\n",
      "  (2, 3614)\t6\n",
      "  (4, 4)\t4\n",
      "  (4, 3614)\t1\n",
      "  (5, 5)\t5\n",
      "  (5, 3614)\t1\n",
      "  (6, 6)\t5\n",
      "  (6, 7)\t2\n",
      "  (6, 14)\t5\n",
      "  (6, 40)\t4\n",
      "  (6, 692)\t5\n",
      "  (6, 3614)\t5\n",
      "  (7, 7)\t3\n",
      "  (7, 64)\t3\n",
      "  (7, 3614)\t2\n",
      "  (8, 8)\t5\n",
      "  (8, 3614)\t1\n",
      "  :\t:\n",
      "  (85063, 3614)\t1\n",
      "  (85064, 144)\t4\n",
      "  (85064, 3614)\t1\n",
      "  (85066, 479)\t5\n",
      "  (85066, 3614)\t1\n",
      "  (85067, 34)\t4\n",
      "  (85067, 3614)\t1\n",
      "  (85068, 219)\t4\n",
      "  (85068, 3614)\t1\n",
      "  (85070, 17)\t4\n",
      "  (85070, 3614)\t1\n",
      "  (85071, 802)\t5\n",
      "  (85071, 3614)\t1\n",
      "  (85073, 156)\t5\n",
      "  (85073, 3614)\t1\n",
      "  (85075, 83)\t3\n",
      "  (85075, 3614)\t1\n",
      "  (85078, 19)\t3\n",
      "  (85078, 3614)\t1\n",
      "  (85079, 131)\t5\n",
      "  (85079, 3614)\t1\n",
      "  (85080, 196)\t4\n",
      "  (85080, 3614)\t1\n",
      "  (85081, 623)\t1\n",
      "  (85081, 3614)\t1\n"
     ]
    }
   ],
   "source": [
    "print (full_csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define similarity function for each given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.5 GiB for an array with shape (5167596996,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[1;32m----> 4\u001b[0m cosine_similarity_matrix_csr \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_csr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1585\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1583\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1585\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:193\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    191\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    196\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m ):\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    544\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:529\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    525\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[0;32m    526\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[0;32m    528\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 529\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    530\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, other\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    532\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 38.5 GiB for an array with shape (5167596996,) and data type int64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "cosine_similarity_matrix_csr = cosine_similarity(ratings_csr_matrix, dense_output=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82286)\t0.8451542547285166\n",
      "  (0, 79940)\t0.8451542547285166\n",
      "  (0, 68527)\t0.8451542547285166\n",
      "  (0, 66537)\t0.4610694459770735\n",
      "  (0, 55180)\t0.8451542547285166\n",
      "  (0, 51297)\t0.8451542547285166\n",
      "  (0, 44975)\t0.629940788348712\n",
      "  (0, 44222)\t0.8451542547285166\n",
      "  (0, 40900)\t0.8451542547285166\n",
      "  (0, 40221)\t0.8451542547285166\n",
      "  (0, 39531)\t0.7247137945655604\n",
      "  (0, 30346)\t0.6444240777830839\n",
      "  (0, 29624)\t0.8451542547285166\n",
      "  (0, 26182)\t0.8451542547285166\n",
      "  (0, 19897)\t0.8451542547285166\n",
      "  (0, 17360)\t0.8017837257372731\n",
      "  (0, 16537)\t0.8451542547285166\n",
      "  (0, 15146)\t0.8451542547285166\n",
      "  (0, 13565)\t0.8451542547285166\n",
      "  (0, 10008)\t0.4161251892882395\n",
      "  (0, 4155)\t0.7247137945655604\n",
      "  (0, 3970)\t0.8451542547285166\n",
      "  (0, 3598)\t0.8451542547285166\n",
      "  (0, 2775)\t0.8451542547285166\n",
      "  (0, 2563)\t0.5279636773484547\n",
      "  :\t:\n",
      "  (85081, 51054)\t1.0\n",
      "  (85081, 47513)\t0.7071067811865475\n",
      "  (85081, 47276)\t1.0\n",
      "  (85081, 44291)\t0.5144957554275265\n",
      "  (85081, 43971)\t1.0\n",
      "  (85081, 42291)\t0.3333333333333333\n",
      "  (85081, 41546)\t1.0\n",
      "  (85081, 41202)\t1.0\n",
      "  (85081, 40768)\t1.0\n",
      "  (85081, 38864)\t0.6246950475544243\n",
      "  (85081, 35445)\t0.7071067811865475\n",
      "  (85081, 35068)\t1.0\n",
      "  (85081, 34949)\t1.0\n",
      "  (85081, 31066)\t0.4472135954999579\n",
      "  (85081, 30000)\t0.4242640687119285\n",
      "  (85081, 29418)\t0.26967994498529685\n",
      "  (85081, 20517)\t1.0\n",
      "  (85081, 17495)\t1.0\n",
      "  (85081, 15868)\t0.7071067811865475\n",
      "  (85081, 15454)\t1.0\n",
      "  (85081, 13683)\t1.0\n",
      "  (85081, 11381)\t0.6666666666666666\n",
      "  (85081, 6856)\t0.6246950475544243\n",
      "  (85081, 5562)\t1.0\n",
      "  (85081, 798)\t0.3481553119113957\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85082, 85082)\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict ratings using similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given movie by a target user, based on the ratings of top-k similar users.\n",
    "    This function uses a pre-calculated similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix.\n",
    "    - similarity_matrix: CSR matrix representing the similarity scores between users.\n",
    "    - user_index: The index of the user for whom the rating is being predicted.\n",
    "    - movie_index: The index of the movie for which the rating is being predicted.\n",
    "    - k: Number of top similar users to consider for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted rating for the movie by the target user.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify users who have rated the movie\n",
    "    movie_rated_indices = csr_user_item_matrix[:, movie_index].nonzero()[0]\n",
    "    \n",
    "    # Check if user_index exists in the similarity matrix\n",
    "    if user_index < 0 or user_index >= similarity_matrix.shape[0]:\n",
    "        # If user_index does not exist in similarity matrix, return default prediction\n",
    "        overall_average_rating = csr_user_item_matrix[:, movie_index].data.mean()\n",
    "        return overall_average_rating if np.isfinite(overall_average_rating) else 3.0  # Assuming 3.0 as a neutral rating\n",
    "    \n",
    "    # Step 2: Extract similarity scores for the target user with all other users\n",
    "    user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "    \n",
    "    # Step 3: Filter the similarities for users who have rated the movie\n",
    "    filtered_similarities = user_similarities[movie_rated_indices]\n",
    "    \n",
    "    # Step 4: Get indices of top k similar users among those who have rated the movie\n",
    "    top_k_indices = np.argsort(filtered_similarities)[-k:]\n",
    "    top_k_users_indices = movie_rated_indices[top_k_indices]\n",
    "    top_k_similarities = filtered_similarities[top_k_indices]\n",
    "\n",
    "    # Retrieve ratings for the movie from these top-k similar users\n",
    "    top_k_ratings = csr_user_item_matrix[top_k_users_indices, movie_index].toarray().flatten()\n",
    "\n",
    "    # Calculate the weighted average rating\n",
    "    weighted_sum = np.dot(top_k_similarities, top_k_ratings)\n",
    "    similarity_sum = np.sum(top_k_similarities)\n",
    "    \n",
    "    if similarity_sum > 0:\n",
    "        predicted_rating = weighted_sum / similarity_sum\n",
    "    else:\n",
    "        # Use the overall average rating of the movie by all users as the default rating\n",
    "        overall_average_rating = csr_user_item_matrix[:, movie_index].data.mean()\n",
    "        predicted_rating = overall_average_rating if np.isfinite(overall_average_rating) else 3.0  # Assuming 3.0 as a neutral rating\n",
    "\n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def evaluate_predictions_csr(validation_data, csr_user_item_matrix, similarity_matrix, k):\n",
    "    \"\"\"\n",
    "    Evaluate the recommendation system by predicting ratings for each user-movie pair in the validation set\n",
    "    using a CSR matrix and pre-computed similarity matrix, and comparing the predictions to the actual ratings using RMSE.\n",
    "\n",
    "    Parameters:\n",
    "    - validation_data: DataFrame containing 'UserIndex', 'MovieIndex', and 'Rating'.\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix from the training set.\n",
    "    - similarity_matrix: Pre-computed similarity matrix as a CSR matrix.\n",
    "    - k: The number of top similar users to consider when making predictions.\n",
    "    \n",
    "    Returns:\n",
    "    - rmse: The root mean square error of the predicted ratings against the actual ratings.\n",
    "    \"\"\"\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "\n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_index = row['UserIndex']\n",
    "        movie_index = row['MovieIndex']\n",
    "        actual_rating = row['Rating']\n",
    "        \n",
    "        # Check if the movie index is valid\n",
    "        if movie_index in csr_user_item_matrix.indices:\n",
    "            predicted_rating = predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            actual_ratings.append(actual_rating)\n",
    "            predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    # Calculate RMSE between actual and predicted ratings\n",
    "    actual_ratings = np.array(actual_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "    valid_mask = ~np.isnan(predicted_ratings)\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings[valid_mask], predicted_ratings[valid_mask]))\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     validation_data_fold \u001b[38;5;241m=\u001b[39m mapped_training_data\u001b[38;5;241m.\u001b[39miloc[test_indices]\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Evaluate predictions on this fold's test set\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_csr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     fold_rmses\u001b[38;5;241m.\u001b[39mappend(rmse)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Calculate average RMSE for this k over all folds\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[96], line 27\u001b[0m, in \u001b[0;36mevaluate_predictions_csr\u001b[1;34m(validation_data, csr_user_item_matrix, similarity_matrix, k)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check if the movie index is valid\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m movie_index \u001b[38;5;129;01min\u001b[39;00m csr_user_item_matrix\u001b[38;5;241m.\u001b[39mindices:\n\u001b[1;32m---> 27\u001b[0m     predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_rating_with_similarity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsr_user_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     actual_ratings\u001b[38;5;241m.\u001b[39mappend(actual_rating)\n\u001b[0;32m     29\u001b[0m     predicted_ratings\u001b[38;5;241m.\u001b[39mappend(predicted_rating)\n",
      "Cell \u001b[1;32mIn[95], line 17\u001b[0m, in \u001b[0;36mpredict_rating_with_similarity_matrix\u001b[1;34m(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mPredict the rating for a given movie by a target user, based on the ratings of top-k similar users.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mThis function uses a pre-calculated similarity matrix.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m- Predicted rating for the movie by the target user.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Identify users who have rated the movie\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m movie_rated_indices \u001b[38;5;241m=\u001b[39m \u001b[43mcsr_user_item_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Check if user_index exists in the similarity matrix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m user_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m similarity_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# If user_index does not exist in similarity matrix, return default prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:65\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_sliceXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m row \u001b[38;5;241m==\u001b[39m col:\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:317\u001b[0m, in \u001b[0;36mcsr_matrix._get_sliceXint\u001b[1;34m(self, row, col)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_sliceXint\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col):\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_submatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_slice(row)\u001b[38;5;241m.\u001b[39m_get_submatrix(minor\u001b[38;5;241m=\u001b[39mcol)\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:810\u001b[0m, in \u001b[0;36m_cs_matrix._get_submatrix\u001b[1;34m(self, major, minor, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i1 \u001b[38;5;241m==\u001b[39m M \u001b[38;5;129;01mand\u001b[39;00m j1 \u001b[38;5;241m==\u001b[39m N:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 810\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((i1 \u001b[38;5;241m-\u001b[39m i0, j1 \u001b[38;5;241m-\u001b[39m j0))\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m    815\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Assuming k_values to test and your similarity matrix is already defined\n",
    "k_values = [5,  50,  200]\n",
    "similarity_matrix = cosine_similarity_matrix_csr\n",
    "# Setup KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    fold_rmses = []  # Store RMSEs for each fold\n",
    "\n",
    "    for train_indices, test_indices in kf.split(ratings_csr_matrix):\n",
    "        # Splitting your data: ratings_csr_matrix doesn't change, so you just map validation set indices\n",
    "        validation_data_fold = mapped_training_data.iloc[test_indices]\n",
    "\n",
    "        # Evaluate predictions on this fold's test set\n",
    "        rmse = evaluate_predictions_csr(validation_data_fold, ratings_csr_matrix, similarity_matrix, k)\n",
    "        fold_rmses.append(rmse)\n",
    "\n",
    "    # Calculate average RMSE for this k over all folds\n",
    "    avg_rmse = np.mean(fold_rmses)\n",
    "    results.append((k, avg_rmse))\n",
    "    print(f\"k={k}, Average RMSE={avg_rmse}\")\n",
    "\n",
    "# Find the best k value based on average RMSE\n",
    "best_k, best_rmse = min(results, key=lambda x: x[1])\n",
    "print(f\"Best k: {best_k} with RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_testing_data = map_ids_to_indices(testing_data, user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity_matrix_csr\n\u001b[0;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Example value for k\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapped_testing_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_csr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[96], line 27\u001b[0m, in \u001b[0;36mevaluate_predictions_csr\u001b[1;34m(validation_data, csr_user_item_matrix, similarity_matrix, k)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check if the movie index is valid\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m movie_index \u001b[38;5;129;01min\u001b[39;00m csr_user_item_matrix\u001b[38;5;241m.\u001b[39mindices:\n\u001b[1;32m---> 27\u001b[0m     predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_rating_with_similarity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsr_user_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     actual_ratings\u001b[38;5;241m.\u001b[39mappend(actual_rating)\n\u001b[0;32m     29\u001b[0m     predicted_ratings\u001b[38;5;241m.\u001b[39mappend(predicted_rating)\n",
      "Cell \u001b[1;32mIn[95], line 17\u001b[0m, in \u001b[0;36mpredict_rating_with_similarity_matrix\u001b[1;34m(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mPredict the rating for a given movie by a target user, based on the ratings of top-k similar users.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mThis function uses a pre-calculated similarity matrix.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m- Predicted rating for the movie by the target user.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Identify users who have rated the movie\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m movie_rated_indices \u001b[38;5;241m=\u001b[39m \u001b[43mcsr_user_item_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Check if user_index exists in the similarity matrix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m user_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m similarity_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# If user_index does not exist in similarity matrix, return default prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:65\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_sliceXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m row \u001b[38;5;241m==\u001b[39m col:\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:317\u001b[0m, in \u001b[0;36mcsr_matrix._get_sliceXint\u001b[1;34m(self, row, col)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_sliceXint\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col):\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_submatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_slice(row)\u001b[38;5;241m.\u001b[39m_get_submatrix(minor\u001b[38;5;241m=\u001b[39mcol)\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:810\u001b[0m, in \u001b[0;36m_cs_matrix._get_submatrix\u001b[1;34m(self, major, minor, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i1 \u001b[38;5;241m==\u001b[39m M \u001b[38;5;129;01mand\u001b[39;00m j1 \u001b[38;5;241m==\u001b[39m N:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 810\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((i1 \u001b[38;5;241m-\u001b[39m i0, j1 \u001b[38;5;241m-\u001b[39m j0))\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m    815\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "similarity_matrix = cosine_similarity_matrix_csr\n",
    "k = 5  # Example value for k\n",
    "rmse = evaluate_predictions_csr(mapped_testing_data, ratings_csr_matrix, similarity_matrix, k)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, user_item_matrix, similarity_matrix, df, N=10):\n",
    "    \"\"\"\n",
    "    Recommend top N movies for a given user using a pre-calculated similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id: The ID of the user for whom to generate recommendations.\n",
    "    - user_item_matrix: DataFrame representing the user-item matrix (users as rows, movies as columns).\n",
    "    - similarity_matrix: DataFrame representing the pre-calculated similarities between users.\n",
    "    - movie_titles: DataFrame or Series mapping MovieIDs to movie titles.\n",
    "    - N: Number of movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples with (MovieID, Movie Title, Predicted Rating) for the top N recommended movies.\n",
    "    \"\"\"\n",
    "    # Ensure user_id is the correct type\n",
    "    user_id = str(user_id)\n",
    "    \n",
    "    # Get the top 25 most similar users to the target user\n",
    "    top_25_users = similarity_matrix.loc[user_id].sort_values(ascending=False).head(25).index\n",
    "    \n",
    "    # Predict ratings for movies the user hasn't seen\n",
    "    predicted_ratings = {}\n",
    "    for movie_id in user_item_matrix.columns:\n",
    "        # Skip if the user has already rated this movie\n",
    "        if not pd.isna(user_item_matrix.at[user_id, movie_id]) and user_item_matrix.at[user_id, movie_id] != 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate the weighted average of ratings from the top 25 similar users\n",
    "        total_weight = 0\n",
    "        weighted_sum = 0\n",
    "        for similar_user in top_25_users:\n",
    "            # Check if the similar user has rated the movie\n",
    "            if pd.isna(user_item_matrix.at[similar_user, movie_id]) or user_item_matrix.at[similar_user, movie_id] == 0:\n",
    "                continue\n",
    "            similarity_score = similarity_matrix.at[user_id, similar_user]\n",
    "            rating = user_item_matrix.at[similar_user, movie_id]\n",
    "            weighted_sum += similarity_score * rating\n",
    "            total_weight += similarity_score\n",
    "        \n",
    "        # Predict the rating if there were any weights, otherwise default to 0\n",
    "        predicted_rating = weighted_sum / total_weight if total_weight > 0 else 0\n",
    "        predicted_ratings[movie_id] = predicted_rating\n",
    "    \n",
    "    # Sort the predicted ratings and select the top N\n",
    "    top_n_recommendations = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    # Fetch the titles for the recommended movies\n",
    "    recommendations = [(movie_id, df[movie_id], rating) for movie_id, rating in top_n_recommendations]\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies2(user_id, user_item_matrix, similarity_matrix, N=10):\n",
    "    \"\"\"\n",
    "    Recommend top N movies for a given user using a pre-calculated similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id: The ID of the user for whom to generate recommendations.\n",
    "    - user_item_matrix: CSR matrix representing the user-item interactions matrix.\n",
    "    - similarity_matrix: CSR matrix representing the pre-calculated similarities between users.\n",
    "    - N: Number of movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples with (MovieID, Predicted Rating) for the top N recommended movies.\n",
    "    \"\"\"\n",
    "    # Get the row corresponding to the user_id\n",
    "    user_index = int(user_id)\n",
    "    similarity_row = similarity_matrix.getrow(user_index)\n",
    "    \n",
    "    # Get indices of top similar users\n",
    "    similar_users_indices = similarity_row.indices[:200]  # Get indices of top 200 similar users\n",
    "    \n",
    "    # Predict ratings for movies the user hasn't seen\n",
    "    predicted_ratings = {}\n",
    "    for movie_id in range(user_item_matrix.shape[1]):\n",
    "        # Skip if the user has already rated this movie\n",
    "        if user_item_matrix[user_index, movie_id] != 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate the weighted average of ratings from the top similar users\n",
    "        total_weight = 0\n",
    "        weighted_sum = 0\n",
    "        for similar_user_index in similar_users_indices:\n",
    "            similarity_score = similarity_matrix[user_index, similar_user_index]\n",
    "            rating = user_item_matrix[similar_user_index, movie_id]\n",
    "            weighted_sum += similarity_score * rating\n",
    "            total_weight += similarity_score\n",
    "        \n",
    "        # Predict the rating if there were any weights, otherwise default to 0\n",
    "        predicted_rating = weighted_sum / total_weight if total_weight > 0 else 0\n",
    "        predicted_ratings[movie_id] = predicted_rating\n",
    "    \n",
    "    # Sort the predicted ratings and select the top N\n",
    "    top_n_recommendations = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    return top_n_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_movies4(df, csr_user_item_matrix, similarity_matrix, user_ids, k, n):\n",
    "    \"\"\"\n",
    "    Recommend top n movies for specified user(s) based on predicted ratings.\n",
    "    Assumes 'UserIndex' and 'MovieIndex' are available in 'df'.\n",
    "    \"\"\"\n",
    "    if not isinstance(user_ids, list):\n",
    "        user_ids = [user_ids]\n",
    "\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            user_index = df[df['CustomerID'] == user_id]['UserIndex'].iloc[0]  # Assuming first matching UserIndex is representative\n",
    "        except IndexError:\n",
    "            print(f\"User ID {user_id} not found.\")\n",
    "            continue\n",
    "\n",
    "        unrated_movies_indices = np.setdiff1d(np.arange(csr_user_item_matrix.shape[1]),\n",
    "                                               csr_user_item_matrix.getrow(user_index).nonzero()[1])\n",
    "        \n",
    "        predicted_ratings = []\n",
    "        for movie_index in unrated_movies_indices:\n",
    "            predicted_rating = predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            movie_id = {v: k for k, v in movie_id_to_index.items()}[movie_index]  # Reverse lookup to get MovieID from MovieIndex\n",
    "            predicted_ratings.append((movie_id, predicted_rating))\n",
    "\n",
    "        top_n_recommendations = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:n]\n",
    "        recommendations[user_id] = top_n_recommendations\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_mapped_data = map_ids_to_indices(strat_sample_df, user_id_to_index, movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the rows (user indices), columns (movie indices), and data (ratings) for the CSR matrix\n",
    "rows = main_mapped_data['UserIndex'].values\n",
    "cols = main_mapped_data['MovieIndex'].values\n",
    "data = main_mapped_data['Rating'].values\n",
    "\n",
    "# Determine the shape of the CSR matrix\n",
    "# The shape is (max_user_index + 1, max_movie_index + 1) because indices start from 0\n",
    "num_users = main_mapped_data['UserIndex'].max() + 1\n",
    "num_movies = main_mapped_data['MovieIndex'].max() + 1\n",
    "\n",
    "# Create the CSR matrix\n",
    "Main_csr_matrix = csr_matrix((data, (rows, cols)), shape=(num_users, num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_similarity_matrix = cosine_similarity(Main_csr_matrix, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85082, 85082)\n"
     ]
    }
   ],
   "source": [
    "print(main_similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>user_activity</th>\n",
       "      <th>AverageMovieAgeRated</th>\n",
       "      <th>user_average_rating</th>\n",
       "      <th>scaled_movie_age</th>\n",
       "      <th>UserActivityBin</th>\n",
       "      <th>Strata</th>\n",
       "      <th>UserIndex</th>\n",
       "      <th>MovieIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8464880</th>\n",
       "      <td>1693</td>\n",
       "      <td>1851346</td>\n",
       "      <td>1</td>\n",
       "      <td>2002-12-15</td>\n",
       "      <td>1998</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.301075</td>\n",
       "      <td>high</td>\n",
       "      <td>high1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311316</th>\n",
       "      <td>1220</td>\n",
       "      <td>1710563</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-12-03</td>\n",
       "      <td>2004</td>\n",
       "      <td>Man on Fire</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.129032</td>\n",
       "      <td>low</td>\n",
       "      <td>low4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17205447</th>\n",
       "      <td>3316</td>\n",
       "      <td>17864</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>2002</td>\n",
       "      <td>Bartleby</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.215054</td>\n",
       "      <td>high</td>\n",
       "      <td>high3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22300142</th>\n",
       "      <td>4227</td>\n",
       "      <td>1673744</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Full Monty</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.258065</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146126</th>\n",
       "      <td>1202</td>\n",
       "      <td>1321440</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>1983</td>\n",
       "      <td>National Lampoon's Vacation</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.032258</td>\n",
       "      <td>low</td>\n",
       "      <td>low4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MovieID CustomerID  Rating        Date  YearOfRelease  \\\n",
       "8464880     1693    1851346       1  2002-12-15           1998   \n",
       "6311316     1220    1710563       4  2004-12-03           2004   \n",
       "17205447    3316      17864       3  2004-01-07           2002   \n",
       "22300142    4227    1673744       4  2000-02-26           1997   \n",
       "6146126     1202    1321440       4  2004-06-25           1983   \n",
       "\n",
       "                           MovieTitle  RatingYear  user_activity  \\\n",
       "8464880                        Sphere        2002              1   \n",
       "6311316                   Man on Fire        2004              1   \n",
       "17205447                     Bartleby        2004              2   \n",
       "22300142               The Full Monty        2000              1   \n",
       "6146126   National Lampoon's Vacation        2004              1   \n",
       "\n",
       "          AverageMovieAgeRated  user_average_rating  scaled_movie_age  \\\n",
       "8464880                      2                    3          1.301075   \n",
       "6311316                      2                    3          1.129032   \n",
       "17205447                     1                    3          1.215054   \n",
       "22300142                     2                    4          1.258065   \n",
       "6146126                      2                    4          2.032258   \n",
       "\n",
       "         UserActivityBin   Strata  UserIndex  MovieIndex  \n",
       "8464880             high    high1          0           0  \n",
       "6311316              low     low4          1           1  \n",
       "17205447            high    high3          2           2  \n",
       "22300142          medium  medium4          3           3  \n",
       "6146126              low     low4          4           4  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_mapped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User ID 1851346:\n",
      "\tMovie ID: 30, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 3122, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 1495, Predicted Rating: 5.000000000000001\n",
      "\tMovie ID: 2780, Predicted Rating: 5.0\n",
      "\tMovie ID: 2342, Predicted Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have 'strat_sample_df', 'Main_csr_matrix', and 'main_similarity_matrix' prepared, along with 'user_id_to_index' and 'movie_id_to_index' mappings:\n",
    "\n",
    "user_ids = ['1851346']  # Single user example\n",
    "# user_ids = ['12345', '67890']  # Multiple users example\n",
    "k = 200  # Number of similar users to consider\n",
    "n = 5  # Number of recommendations to generate\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = recommend_movies4(main_mapped_data, Main_csr_matrix, main_similarity_matrix, user_ids, k, n)\n",
    "\n",
    "# Display the recommendations\n",
    "for user_id in user_ids:\n",
    "    print(f\"Recommendations for User ID {user_id}:\")\n",
    "    if user_id in recommendations:\n",
    "        for movie_id, predicted_rating in recommendations[user_id]:\n",
    "            print(f\"\\tMovie ID: {movie_id}, Predicted Rating: {predicted_rating}\")\n",
    "    else:\n",
    "        print(\"\\tNo recommendations available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
