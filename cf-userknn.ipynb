{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>MovieAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>2003</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  CustomerID  Rating        Date  YearOfRelease  RatingYear  \\\n",
       "0        1     1488844       3  2005-09-06           2003        2005   \n",
       "1        1      822109       5  2005-05-13           2003        2005   \n",
       "2        1      885013       4  2005-10-19           2003        2005   \n",
       "3        1       30878       4  2005-12-26           2003        2005   \n",
       "4        1      823519       3  2004-05-03           2003        2004   \n",
       "\n",
       "   MovieAge  \n",
       "0         2  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_df = pd.read_csv('C:/Users/nafla/OneDrive/Documents/system development/Netflix/training_data.csv')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     8.0\n",
      "0.50    24.0\n",
      "0.75    64.0\n",
      "Name: CustomerID, dtype: float64\n",
      "0.25     192.0\n",
      "0.50     552.5\n",
      "0.75    2539.0\n",
      "Name: MovieID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate quantiles for user activity and item popularity\n",
    "user_activity_quantiles = training_df['CustomerID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "item_popularity_quantiles = training_df['MovieID'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "print(user_activity_quantiles)\n",
    "print(item_popularity_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['CustomerID'] = training_df['CustomerID'].astype(str)\n",
    "training_df['MovieID'] = training_df['MovieID'].astype(str)\n",
    "training_df['Rating'] = pd.to_numeric(training_df['Rating'], errors='coerce')  # Converts to float, makes non-numeric as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion:\n",
      "MovieID          object\n",
      "CustomerID       object\n",
      "Rating            int64\n",
      "Date             object\n",
      "YearOfRelease     int64\n",
      "RatingYear        int64\n",
      "MovieAge          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Before conversion:\")\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampling Method \n",
    "\n",
    "To create a representative sample of our dataset, we employ a stratified sampling method that accounts for three key dimensions: Rating Distribution, User Activity, and Item Popularity. This approach ensures our sample maintains the diversity and characteristics of the entire dataset, facilitating more reliable model training and evaluation.\n",
    "\n",
    "- User Activity is quantified by the number of ratings a user has provided.\n",
    "- Item Popularity reflects the number of ratings an item has received.\n",
    "\n",
    "Finally, We combine User Activity, Item Popularity, and Rating into a composite stratification key for each record. This multi-dimensional key ensures our sampling process considers the distribution across all three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each user and item to a bin based on the quantiles\n",
    "training_df['UserActivityBin'] = pd.qcut(training_df.groupby('CustomerID')['Rating'].transform('size'), \n",
    "                                q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "training_df['ItemPopularityBin'] = pd.qcut(training_df.groupby('MovieID')['Rating'].transform('size'), \n",
    "                                  q=[0, .25, .5, .75, 1], labels=['low', 'medium', 'medium-high', 'high'])\n",
    "\n",
    "# Combine these with Rating to create a stratification key\n",
    "training_df['Strata'] = training_df['UserActivityBin'].astype(str) + \"_\" + training_df['ItemPopularityBin'].astype(str) + \"_\" + training_df['Rating'].astype(str)\n",
    "\n",
    "# Perform stratified sampling\n",
    "# we use groupby and  frac to specify a fraction of each strata and in case number of rows is less that 10 it takes all rows\n",
    "strat_sample_df = training_df.groupby('Strata').apply(lambda x: x.sample(frac=0.005 if len(x) > 10 else len(x)/len(x))).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the sampled DataFrame: 120269\n"
     ]
    }
   ],
   "source": [
    "num_sampled_rows = len(strat_sample_df)\n",
    "print(f\"Number of rows in the sampled DataFrame: {num_sampled_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset to training, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the remaining data into training, testing, and validation sets\n",
    "training_data, testing_data = train_test_split(strat_sample_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 96215\n",
      "Testing Data Size: 24054\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of each split\n",
    "training_size = training_data.shape[0]  # Number of rows in the training data\n",
    "# validation_size = validation_data.shape[0]  # Number of rows in the validation data\n",
    "testing_size = testing_data.shape[0]  # Number of rows in the testing data\n",
    "\n",
    "# Print the sizes\n",
    "print(f\"Training Data Size: {training_size}\")\n",
    "# print(f\"Validation Data Size: {validation_size}\")\n",
    "print(f\"Testing Data Size: {testing_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CustomerIDs in Training Data: 74762\n",
      "Unique MovieIDs in Testing Data: 2329\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_training_data, validation_data, and testing_data are your data splits\n",
    "\n",
    "# Count unique MovieIDs in the final training data\n",
    "unique_movies_training = training_data['CustomerID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the validation data\n",
    "# unique_movies_validation = validation_data['MovieID'].nunique()\n",
    "\n",
    "# Count unique MovieIDs in the testing data\n",
    "unique_movies_testing = testing_data['MovieID'].nunique()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Unique CustomerIDs in Training Data: {unique_movies_training}\")\n",
    "# print(f\"Unique MovieIDs in Validation Data: {unique_movies_validation}\")\n",
    "print(f\"Unique MovieIDs in Testing Data: {unique_movies_testing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating User - Item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t4\n",
      "  (1, 1)\t5\n",
      "  (1, 128)\t5\n",
      "  (2, 2)\t4\n",
      "  (3, 3)\t4\n",
      "  (3, 26)\t4\n",
      "  (4, 4)\t2\n",
      "  (4, 179)\t4\n",
      "  (5, 5)\t4\n",
      "  (6, 6)\t3\n",
      "  (6, 458)\t3\n",
      "  (7, 7)\t3\n",
      "  (8, 8)\t5\n",
      "  (9, 9)\t3\n",
      "  (9, 1586)\t4\n",
      "  (10, 10)\t4\n",
      "  (10, 2638)\t3\n",
      "  (11, 11)\t4\n",
      "  (12, 12)\t3\n",
      "  (12, 35)\t4\n",
      "  (13, 13)\t2\n",
      "  (13, 48)\t4\n",
      "  (13, 660)\t3\n",
      "  (13, 1740)\t2\n",
      "  (13, 1960)\t2\n",
      "  :\t:\n",
      "  (74737, 1578)\t1\n",
      "  (74738, 14)\t3\n",
      "  (74739, 71)\t5\n",
      "  (74740, 37)\t4\n",
      "  (74741, 321)\t5\n",
      "  (74742, 174)\t4\n",
      "  (74743, 42)\t3\n",
      "  (74744, 27)\t3\n",
      "  (74745, 301)\t3\n",
      "  (74746, 154)\t3\n",
      "  (74747, 824)\t3\n",
      "  (74748, 180)\t5\n",
      "  (74749, 247)\t3\n",
      "  (74750, 203)\t1\n",
      "  (74751, 579)\t4\n",
      "  (74752, 75)\t4\n",
      "  (74753, 161)\t5\n",
      "  (74754, 198)\t5\n",
      "  (74755, 1174)\t4\n",
      "  (74756, 197)\t5\n",
      "  (74757, 114)\t4\n",
      "  (74758, 186)\t4\n",
      "  (74759, 1969)\t5\n",
      "  (74760, 37)\t3\n",
      "  (74761, 264)\t2\n"
     ]
    }
   ],
   "source": [
    "# Creating customer-movie matrix\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# Map user IDs and movie IDs to integer indices for CSR matrix\n",
    "user_ids = training_data['CustomerID'].unique()\n",
    "movie_ids = training_data['MovieID'].unique()\n",
    "\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "# Prepare row, column, and data arrays for csr_matrix\n",
    "rows = training_data['CustomerID'].map(user_id_to_index)\n",
    "cols = training_data['MovieID'].map(movie_id_to_index)\n",
    "data = training_data['Rating']\n",
    "\n",
    "# Create CSR matrix\n",
    "ratings_csr_matrix = csr_matrix((data, (rows, cols)), shape=(len(user_ids), len(movie_ids)))\n",
    "\n",
    "\n",
    "print(ratings_csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define similarity function for each given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "cosine_similarity_matrix_csr = cosine_similarity(ratings_csr_matrix, dense_output=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 72861)\t1.0\n",
      "  (0, 72688)\t1.0\n",
      "  (0, 71762)\t1.0\n",
      "  (0, 71152)\t1.0\n",
      "  (0, 70407)\t1.0\n",
      "  (0, 70130)\t1.0\n",
      "  (0, 69721)\t1.0\n",
      "  (0, 69673)\t1.0\n",
      "  (0, 68551)\t0.7071067811865475\n",
      "  (0, 67891)\t1.0\n",
      "  (0, 67832)\t1.0\n",
      "  (0, 67747)\t1.0\n",
      "  (0, 67572)\t1.0\n",
      "  (0, 66904)\t1.0\n",
      "  (0, 65637)\t1.0\n",
      "  (0, 65604)\t1.0\n",
      "  (0, 64342)\t1.0\n",
      "  (0, 64185)\t1.0\n",
      "  (0, 64131)\t1.0\n",
      "  (0, 64054)\t0.8320502943378437\n",
      "  (0, 64028)\t0.9486832980505138\n",
      "  (0, 63894)\t1.0\n",
      "  (0, 62700)\t1.0\n",
      "  (0, 60965)\t1.0\n",
      "  (0, 60786)\t1.0\n",
      "  :\t:\n",
      "  (74761, 8934)\t0.6\n",
      "  (74761, 8642)\t0.5144957554275265\n",
      "  (74761, 8517)\t0.3651483716701107\n",
      "  (74761, 8387)\t1.0\n",
      "  (74761, 8020)\t1.0\n",
      "  (74761, 7527)\t0.39056673294247163\n",
      "  (74761, 7518)\t0.4242640687119285\n",
      "  (74761, 6612)\t1.0\n",
      "  (74761, 6271)\t0.8574929257125441\n",
      "  (74761, 6102)\t0.7071067811865475\n",
      "  (74761, 5291)\t0.5298129428260175\n",
      "  (74761, 4849)\t1.0\n",
      "  (74761, 4708)\t0.5883484054145521\n",
      "  (74761, 4486)\t1.0\n",
      "  (74761, 3638)\t0.31622776601683794\n",
      "  (74761, 3620)\t0.5298129428260175\n",
      "  (74761, 3414)\t0.4472135954999579\n",
      "  (74761, 2301)\t1.0\n",
      "  (74761, 2163)\t0.7071067811865476\n",
      "  (74761, 1846)\t1.0\n",
      "  (74761, 1358)\t0.4082482904638631\n",
      "  (74761, 829)\t0.34299717028501764\n",
      "  (74761, 535)\t1.0\n",
      "  (74761, 362)\t0.5773502691896257\n",
      "  (74761, 25)\t0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix_df = training_data.pivot_table(index='CustomerID', columns='MovieID', values='Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_user_corr_matrix = user_item_matrix_df.corr()  # Use Pearson correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 7)\t1.0\n",
      "  (9, 9)\t1.0\n",
      "  (11, 11)\t1.0\n",
      "  (12, 12)\t1.0\n",
      "  (13, 13)\t1.0\n",
      "  (15, 15)\t1.0\n",
      "  (16, 16)\t1.0\n",
      "  (17, 17)\t1.0\n",
      "  (18, 18)\t1.0\n",
      "  (20, 20)\t1.0\n",
      "  (21, 21)\t1.0\n",
      "  (22, 22)\t1.0\n",
      "  (24, 24)\t1.0\n",
      "  (25, 25)\t1.0\n",
      "  (26, 26)\t1.0\n",
      "  (27, 27)\t1.0\n",
      "  (27, 804)\t1.0\n",
      "  (28, 28)\t1.0\n",
      "  (29, 29)\t1.0\n",
      "  (30, 30)\t1.0\n",
      "  :\t:\n",
      "  (3471, 3471)\t1.0\n",
      "  (3472, 3472)\t1.0\n",
      "  (3473, 3473)\t1.0\n",
      "  (3474, 541)\t1.0\n",
      "  (3474, 1189)\t0.8660254037844387\n",
      "  (3474, 2085)\t1.0\n",
      "  (3474, 2239)\t1.0\n",
      "  (3474, 2688)\t1.0\n",
      "  (3474, 3014)\t-1.0\n",
      "  (3474, 3025)\t0.3333333333333334\n",
      "  (3474, 3122)\t0.5000000000000001\n",
      "  (3474, 3200)\t1.0\n",
      "  (3474, 3433)\t1.0\n",
      "  (3474, 3474)\t1.0\n",
      "  (3475, 3475)\t1.0\n",
      "  (3476, 3476)\t1.0\n",
      "  (3477, 3477)\t1.0\n",
      "  (3478, 3478)\t1.0\n",
      "  (3479, 3479)\t1.0\n",
      "  (3480, 3480)\t1.0\n",
      "  (3481, 3481)\t1.0\n",
      "  (3482, 3482)\t1.0\n",
      "  (3484, 1987)\t1.0\n",
      "  (3484, 3484)\t1.0\n",
      "  (3485, 3485)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert to sparse matrix format if needed\n",
    "pearson_similarity_matrix = csr_matrix(user_user_corr_matrix.fillna(0).values)\n",
    "\n",
    "print(pearson_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3486, 3486)\n"
     ]
    }
   ],
   "source": [
    "print(pearson_similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict ratings using similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given movie by a target user, based on the ratings of top-k similar users.\n",
    "    This function uses a pre-calculated similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix.\n",
    "    - similarity_matrix: CSR matrix representing the similarity scores between users.\n",
    "    - user_index: The index of the user for whom the rating is being predicted.\n",
    "    - movie_index: The index of the movie for which the rating is being predicted.\n",
    "    - k: Number of top similar users to consider for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted rating for the movie by the target user.\n",
    "    \"\"\"\n",
    "    num_users = similarity_matrix.shape[0]  # Number of users in the similarity matrix\n",
    "    \n",
    "    # Check if user_index exists in the similarity matrix\n",
    "    if user_index >= 0 and user_index < num_users:\n",
    "        # Extract similarity scores for the target user\n",
    "        user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "    else:\n",
    "        # If user_index does not exist, consider the similarity scores as zeros\n",
    "        user_similarities = np.zeros(num_users)\n",
    "    # # Extract similarity scores for the target user and sort them to find top k similar users\n",
    "    # user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "    top_k_users_indices = np.argsort(user_similarities)[-k:]\n",
    "#     # Step 1: Extract all user indices who have rated the movie\n",
    "#     users_who_rated_movie_indices = np.flatnonzero(csr_user_item_matrix[:, movie_index].toarray().flatten() > 0)\n",
    "\n",
    "# # Step 2: Extract similarity scores for the target user\n",
    "#     user_similarities = similarity_matrix.getrow(user_index).toarray().flatten()\n",
    "\n",
    "# # Filter similarities for users who have rated the movie\n",
    "#     filtered_similarities = user_similarities[users_who_rated_movie_indices]\n",
    "\n",
    "# # Check if there are enough users who rated the movie\n",
    "#     if len(filtered_similarities) >= k:\n",
    "#         # Step 3: Find indices of top k similar users from the filtered list\n",
    "#         # Since we are working with filtered indices, we need to sort them based on similarity and then map back to the original user indices\n",
    "#         top_k_filtered_indices = np.argsort(filtered_similarities)[-k:]\n",
    "\n",
    "#         # Map back to original indices in the user_item_matrix\n",
    "#         top_k_users_indices = users_who_rated_movie_indices[top_k_filtered_indices]\n",
    "#     else:\n",
    "#         # If there are fewer than k users, use all available users\n",
    "#         top_k_users_indices = users_who_rated_movie_indices\n",
    "\n",
    "    # Get ratings of the movie from all users\n",
    "    movie_ratings = csr_user_item_matrix.getcol(movie_index).toarray().flatten()\n",
    "\n",
    "    # Calculate weighted average of ratings\n",
    "    top_k_similarities = user_similarities[top_k_users_indices]\n",
    "    top_k_ratings = movie_ratings[top_k_users_indices]\n",
    "    \n",
    "    weighted_sum = np.dot(top_k_similarities, top_k_ratings)\n",
    "    similarity_sum = np.sum(top_k_similarities)\n",
    "\n",
    "    if similarity_sum > 0:\n",
    "        predicted_rating = weighted_sum / similarity_sum\n",
    "\n",
    "    else:\n",
    "        # Use the overall average rating of the movie by all users as the default rating\n",
    "        overall_average_rating = csr_user_item_matrix[:, movie_index].mean()\n",
    "        predicted_rating = overall_average_rating if np.isfinite(overall_average_rating) else 5\n",
    "  # Default rating this is the problem \n",
    "    \n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def evaluate_predictions_csr(validation_data, csr_user_item_matrix, similarity_matrix, k, user_id_to_index, movie_id_to_index):\n",
    "    \"\"\"\n",
    "    Evaluate the recommendation system by predicting ratings for each user-movie pair in the validation set\n",
    "    using a CSR matrix and pre-computed similarity matrix, and comparing the predictions to the actual ratings using RMSE.\n",
    "\n",
    "    Parameters:\n",
    "    - validation_data: DataFrame containing 'UserIndex', 'MovieIndex', and 'Rating'.\n",
    "    - csr_user_item_matrix: CSR matrix representing the user-item matrix from the training set.\n",
    "    - similarity_matrix: Pre-computed similarity matrix as a CSR matrix.\n",
    "    - k: The number of top similar users to consider when making predictions.\n",
    "    - user_id_to_index: Dictionary mapping user IDs to indices.\n",
    "    - movie_id_to_index: Dictionary mapping movie IDs to indices.\n",
    "    \n",
    "    Returns:\n",
    "    - rmse: The root mean square error of the predicted ratings against the actual ratings.\n",
    "    \"\"\"\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "\n",
    "    for _, row in validation_data.iterrows():\n",
    "        user_index = row['UserIndex']\n",
    "        movie_index = row['MovieIndex']\n",
    "        actual_rating = row['Rating']\n",
    "        \n",
    "        # Check if the movie index is valid\n",
    "        if movie_index in csr_user_item_matrix.indices:\n",
    "            predicted_rating = predict_rating_with_similarity_matrix(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\n",
    "            actual_ratings.append(actual_rating)\n",
    "            predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    # Calculate RMSE between actual and predicted ratings\n",
    "    actual_ratings = np.array(actual_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "    valid_mask = ~np.isnan(predicted_ratings)\n",
    "    rmse = sqrt(mean_squared_error(actual_ratings[valid_mask], predicted_ratings[valid_mask]))\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids_to_indices(validation_data, user_id_to_index, movie_id_to_index):\n",
    "    \"\"\"\n",
    "    Map user IDs and movie IDs to their respective indices.\n",
    "\n",
    "    Parameters:\n",
    "    - validation_data: DataFrame containing 'CustomerID', 'MovieID', and other columns.\n",
    "    - user_id_to_index: Dictionary mapping user IDs to indices.\n",
    "    - movie_id_to_index: Dictionary mapping movie IDs to indices.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with added columns 'UserIndex' and 'MovieIndex' for the respective indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    modified_data = validation_data.copy()\n",
    "    \n",
    "    # Map 'CustomerID' to 'UserIndex'\n",
    "    modified_data['UserIndex'] = modified_data['CustomerID'].map(user_id_to_index)\n",
    "    \n",
    "    # Map 'MovieID' to 'MovieIndex'\n",
    "    modified_data['MovieIndex'] = modified_data['MovieID'].map(movie_id_to_index)\n",
    "    \n",
    "    # Optional: drop rows where either UserIndex or MovieIndex is NaN (i.e., ID wasn't found)\n",
    "    modified_data.dropna(subset=['UserIndex', 'MovieIndex'], inplace=True)\n",
    "    \n",
    "    # Convert indices to integers (they might be floats due to NaN handling)\n",
    "    modified_data['UserIndex'] = modified_data['UserIndex'].astype(int)\n",
    "    modified_data['MovieIndex'] = modified_data['MovieIndex'].astype(int)\n",
    "    \n",
    "    return modified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data = map_ids_to_indices(training_data, user_id_to_index, movie_id_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(mapped_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfRelease</th>\n",
       "      <th>RatingYear</th>\n",
       "      <th>MovieAge</th>\n",
       "      <th>UserActivityBin</th>\n",
       "      <th>ItemPopularityBin</th>\n",
       "      <th>Strata</th>\n",
       "      <th>UserIndex</th>\n",
       "      <th>MovieIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76827</th>\n",
       "      <td>985</td>\n",
       "      <td>939486</td>\n",
       "      <td>3</td>\n",
       "      <td>2002-11-04</td>\n",
       "      <td>1999</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>medium-high</td>\n",
       "      <td>medium-high</td>\n",
       "      <td>medium-high_medium-high_3</td>\n",
       "      <td>54219</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52655</th>\n",
       "      <td>2342</td>\n",
       "      <td>570275</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-11-22</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>medium-high</td>\n",
       "      <td>low_medium-high_5</td>\n",
       "      <td>18542</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94920</th>\n",
       "      <td>4123</td>\n",
       "      <td>2501691</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-12-18</td>\n",
       "      <td>1998</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>medium_high_4</td>\n",
       "      <td>6317</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47822</th>\n",
       "      <td>1975</td>\n",
       "      <td>1574990</td>\n",
       "      <td>2</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>2000</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "      <td>medium-high</td>\n",
       "      <td>low_medium-high_2</td>\n",
       "      <td>1163</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67318</th>\n",
       "      <td>12</td>\n",
       "      <td>569566</td>\n",
       "      <td>2</td>\n",
       "      <td>2003-09-04</td>\n",
       "      <td>1947</td>\n",
       "      <td>2003</td>\n",
       "      <td>56</td>\n",
       "      <td>medium-high</td>\n",
       "      <td>low</td>\n",
       "      <td>medium-high_low_2</td>\n",
       "      <td>14719</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MovieID CustomerID  Rating        Date  YearOfRelease  RatingYear  \\\n",
       "76827     985     939486       3  2002-11-04           1999        2002   \n",
       "52655    2342     570275       5  2004-11-22           2004        2004   \n",
       "94920    4123    2501691       4  2001-12-18           1998        2001   \n",
       "47822    1975    1574990       2  2005-10-24           2000        2005   \n",
       "67318      12     569566       2  2003-09-04           1947        2003   \n",
       "\n",
       "       MovieAge UserActivityBin ItemPopularityBin                     Strata  \\\n",
       "76827         3     medium-high       medium-high  medium-high_medium-high_3   \n",
       "52655         0             low       medium-high          low_medium-high_5   \n",
       "94920         3          medium              high              medium_high_4   \n",
       "47822         5             low       medium-high          low_medium-high_2   \n",
       "67318        56     medium-high               low          medium-high_low_2   \n",
       "\n",
       "       UserIndex  MovieIndex  \n",
       "76827      54219         197  \n",
       "52655      18542         103  \n",
       "94920       6317         310  \n",
       "47822       1163         211  \n",
       "67318      14719        1714  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m pearson_similarity_matrix\n\u001b[0;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Example value for k\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_csr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id_to_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_id_to_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m, in \u001b[0;36mevaluate_predictions_csr\u001b[1;34m(validation_data, csr_user_item_matrix, similarity_matrix, k, user_id_to_index, movie_id_to_index)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Check if the movie index is valid\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m movie_index \u001b[38;5;129;01min\u001b[39;00m csr_user_item_matrix\u001b[38;5;241m.\u001b[39mindices:\n\u001b[1;32m---> 29\u001b[0m     predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_rating_with_similarity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsr_user_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     actual_ratings\u001b[38;5;241m.\u001b[39mappend(actual_rating)\n\u001b[0;32m     31\u001b[0m     predicted_ratings\u001b[38;5;241m.\u001b[39mappend(predicted_rating)\n",
      "Cell \u001b[1;32mIn[44], line 50\u001b[0m, in \u001b[0;36mpredict_rating_with_similarity_matrix\u001b[1;34m(csr_user_item_matrix, similarity_matrix, user_index, movie_index, k)\u001b[0m\n\u001b[0;32m     27\u001b[0m     top_k_users_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(user_similarities)[\u001b[38;5;241m-\u001b[39mk:]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#     # Step 1: Extract all user indices who have rated the movie\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     users_who_rated_movie_indices = np.flatnonzero(csr_user_item_matrix[:, movie_index].toarray().flatten() > 0)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Get ratings of the movie from all users\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     movie_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mcsr_user_item_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Calculate weighted average of ratings\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     top_k_similarities \u001b[38;5;241m=\u001b[39m user_similarities[top_k_users_indices]\n",
      "File \u001b[1;32mc:\\Users\\nafla\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:274\u001b[0m, in \u001b[0;36mcsr_matrix.getcol\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m i)\n\u001b[1;32m--> 274\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39m(M, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    277\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "similarity_matrix = pearson_similarity_matrix\n",
    "k = 10  # Example value for k\n",
    "rmse = evaluate_predictions_csr(validation_data, ratings_csr_matrix, similarity_matrix, k, user_id_to_index, movie_id_to_index)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for k=5: 1.517477072883225\n",
      "RMSE for k=30: 1.5173909880664258\n",
      "RMSE for k=70: 1.5173909880664258\n",
      "RMSE for k=150: 1.5173909880664258\n",
      "RMSE for k=200: 1.5173909880664258\n",
      "RMSE for k=300: 1.5173909880664258\n",
      "RMSE for k=500: 1.5173909880664258\n",
      "\n",
      "Optimal k value: 30 with RMSE: 1.5173909880664258\n"
     ]
    }
   ],
   "source": [
    "# Define a range of k values to test\n",
    "k_values = [ 5, 30, 70, 150, 200, 300, 500]\n",
    "\n",
    "# Initialize a dictionary to store the RMSE for each k value\n",
    "k_rmse_results = {}\n",
    "\n",
    "# Loop over each k value\n",
    "for k in k_values:\n",
    "    # Evaluate the recommender system using the current k value\n",
    "    rmse = evaluate_predictions_csr(validation_data, ratings_csr_matrix, similarity_matrix, k, user_id_to_index, movie_id_to_index)\n",
    "\n",
    "    # Store the RMSE in the dictionary\n",
    "    k_rmse_results[k] = rmse\n",
    "    \n",
    "    # Print the result for the current k\n",
    "    print(f\"RMSE for k={k}: {rmse}\")\n",
    "\n",
    "# Identify the k value with the lowest RMSE\n",
    "optimal_k = min(k_rmse_results, key=k_rmse_results.get)\n",
    "optimal_rmse = k_rmse_results[optimal_k]\n",
    "\n",
    "print(f\"\\nOptimal k value: {optimal_k} with RMSE: {optimal_rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a dictionary to hold your similarity methods for easy access\n",
    "similarity_methods = {\n",
    "    'pearson': calculate_pearson_similarity,\n",
    "    'cosine': calculate_cosine_similarity,\n",
    "    'manhattan': calculate_manhattan_similarity  \n",
    "}\n",
    "\n",
    "# Define the range of k values you want to test\n",
    "k_values = range(5, 300, 20)\n",
    "\n",
    "# Placeholder for storing grid search results\n",
    "grid_search_results = []\n",
    "\n",
    "# Perform grid search\n",
    "for k in k_values:\n",
    "    for method_name, method_function in similarity_methods.items():\n",
    "        # Evaluate the recommender system's performance for each combination of k and similarity method\n",
    "        rmse = evaluate_predictions(validation_data, user_item_matrix, k, method_function)\n",
    "        \n",
    "        # Store the results\n",
    "        grid_search_results.append({'method': method_name, 'k': k, 'rmse': rmse})\n",
    "        \n",
    "        # Optionally print the results for each iteration\n",
    "        print(f\"Evaluated {method_name} method with k={k}: RMSE = {rmse}\")\n",
    "\n",
    "# Find the best performing combination of k and similarity method based on RMSE\n",
    "best_configuration = min(grid_search_results, key=lambda x: x['rmse'])\n",
    "\n",
    "# Output the best combination found\n",
    "print(f\"Best Configuration: Method = {best_configuration['method']}, k = {best_configuration['k']}, RMSE = {best_configuration['rmse']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def calculate_pearson_similarity_matrix_sparse(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficient between all pairs of users' ratings in the user-item matrix.\n",
    "    Only non-zero similarities are stored in a sparse matrix, making it more memory-efficient.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_item_matrix: DataFrame with users as rows, movies as columns, and ratings as values.\n",
    "    \n",
    "    Returns:\n",
    "    - similarity_matrix_sparse: A sparse matrix representing the user-user similarity matrix using Pearson correlation coefficients.\n",
    "    \"\"\"\n",
    "    # Replace 0 with NaN to ignore unrated items in the correlation computation\n",
    "    user_item_matrix_replaced = user_item_matrix.replace(0, np.nan)\n",
    "    \n",
    "    # Initialize a sparse matrix for storing similarities\n",
    "    n_users = user_item_matrix_replaced.shape[0]\n",
    "    similarity_matrix_sparse = lil_matrix((n_users, n_users))\n",
    "    \n",
    "    user_indices = {user_id: index for index, user_id in enumerate(user_item_matrix_replaced.index)}\n",
    "    \n",
    "    # Loop through each pair of users to calculate similarity\n",
    "    for user1 in user_item_matrix_replaced.index:\n",
    "        for user2 in user_item_matrix_replaced.index:\n",
    "            if user1 != user2:\n",
    "                user1_ratings = user_item_matrix_replaced.loc[user1]\n",
    "                user2_ratings = user_item_matrix_replaced.loc[user2]\n",
    "                \n",
    "                # Find common movies rated by both users\n",
    "                common_movies = user1_ratings.dropna().index.intersection(user2_ratings.dropna().index)\n",
    "                \n",
    "                if len(common_movies) >= 2:\n",
    "                    # Calculate Pearson correlation for common rated movies\n",
    "                    correlation, _ = pearsonr(user1_ratings.loc[common_movies], user2_ratings.loc[common_movies])\n",
    "                    \n",
    "                    # Store the correlation if it's valid and non-zero\n",
    "                    if np.isfinite(correlation) and correlation != 0:\n",
    "                        similarity_matrix_sparse[user_indices[user1], user_indices[user2]] = correlation\n",
    "                # No need to explicitly set values for pairs with fewer than 2 common ratings or for NaN correlations\n",
    "            else:\n",
    "                # Set self-similarity to 1\n",
    "                similarity_matrix_sparse[user_indices[user1], user_indices[user2]] = 1\n",
    "                \n",
    "    return similarity_matrix_sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = calculate_pearson_similarity_matrix_sparse (user_item_matrix)\n",
    "similarity_matrix.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
